# -*- coding: utf-8 -*-
"""B21CS033_B21CS007_Minor_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nS7DA_RUWgZ0Glv9X-gx6768TGUnTJ_u
"""

from google.colab import drive
drive.mount('/content/drive')

"""We have added section headings and texts to make code well documented. you can reffer Table of Contents for the same.

# Data Loading and Analysis
"""

#importing dependencies
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.figure_factory as ff
from plotly import tools
import plotly 
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
init_notebook_mode(connected=True)
from mpl_toolkits.mplot3d import Axes3D

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from pandas.core.internals import concat

import matplotlib.pyplot as plt
import numpy
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import RocCurveDisplay

"""Loading Dataset"""

credit_df = pd.read_csv('/content/drive/MyDrive/PRML lab data /Minor Project /creditcard.csv')
credit_df

"""Data about Dataset"""

#satistics of dataset
credit_df.describe()

#Datatype and non-null rows for each column
credit_df.info()

#count of null values in each column
credit_df.isnull().sum()

"""There is no NULL values in any column

Number of Normal and Fraudulent transections
"""

#count of each class in the dataset
credit_df['Class'].value_counts()

"""There are 284315 Normal transactions and only 492 Farudulent transactions. 


---

The Dataset is highly unbalanced.
"""

#percentage of normal transaction and fraud transaction in dataset
print('Normal', round(credit_df['Class'].value_counts()[0]/len(credit_df) * 100,2), '% of the dataset')
print('Frauds', round(credit_df['Class'].value_counts()[1]/len(credit_df) * 100,2), '% of the dataset')

"""# Visualisation of Data"""

fig, ax = plt.subplots(1, 2, figsize=(18,4))

amount_val = credit_df['Amount'].values
time_val = credit_df['Time'].values

#density plot of transaction amount
sns.distplot(amount_val, ax=ax[0], color='red')
ax[0].set_title('Distribution of Transaction Amount', fontsize=14)
ax[0].set_xlim([min(amount_val), max(amount_val)])

#density plot of transaction time
sns.distplot(time_val, ax=ax[1], color='green')
ax[1].set_title('Distribution of Transaction Time', fontsize=14)
ax[1].set_xlim([min(time_val), max(time_val)])

var = credit_df.columns.values

i = 0
t0 = credit_df.loc[credit_df['Class'] == 0]
t1 = credit_df.loc[credit_df['Class'] == 1]

sns.set_style('whitegrid')
plt.figure()
fig, ax = plt.subplots(6,5,figsize=(20,35))

#density plot of each feature
for feature in var:
    if(feature!='Class'):
        i += 1
        plt.subplot(6,5,i)
        sns.kdeplot(t0[feature], bw_method=0.5,label="Class = 0")
        sns.kdeplot(t1[feature], bw_method=0.5,label="Class = 1")
        plt.xlabel(feature, fontsize=12)
        locs, labels = plt.xticks()
        plt.tick_params(axis='both', which='major', labelsize=12)
        plt.legend()
plt.show();

# Function to plot scatter Matrix
def plotScatterMatrix(df, plotSize, textSize):
    df = df.select_dtypes(include =[np.number])

    df = df.dropna('columns')
    df = df[[col for col in df if df[col].nunique() > 1]] 
    columnNames = list(df)
    if len(columnNames) > 10: 
        columnNames = columnNames[:10]
    df = df[columnNames]
    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')
    corrs = df.corr().values
    
    plt.suptitle('Scatter and Density Plot')
    plt.show()

#Scatter Matrix plot of some of the features with each other
plotScatterMatrix(credit_df, 20, 10)

"""Plotting Correlation Heatmap of the Dataset"""

corr = credit_df.corr()
plt.figure(figsize=(24, 12))
heatmap = sns.heatmap(corr, vmin=-1, vmax=1, annot=True,cmap='BrBG')
heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':20}, pad=12);

"""From Correlation Heatmap we can infer that : 

---


1.   V2 V4 V11 and V19 are more positively correlated with class 
2.   V10 V12 V14 and V17 are more negatively correlated with class

---

 
*   This means higher the value of (V2 ,V4 ,V11 ,V19) the more its likely to belong to Fraudulent class.
*   This also means lower the value of (V10 ,V12 ,V14 ,V17) the more its likely to belong to Fraudulent class.

Sepearting the classes
"""

Normal_df = credit_df[credit_df['Class']==0]
Normal_df

Fraud_df = credit_df[credit_df['Class']==1]
Fraud_df

"""Some Statistical Analysis"""

Normal_df.Amount.describe()

Fraud_df.Amount.describe()

"""Comparing the Values for classes"""

#comparing values of means for each feature for both classes
credit_df.groupby('Class').mean()

"""We can see that Mean of all the columns for Normal Transactions is much less than Fraudulent Transactions.

# Pre-Processing Dataset
"""

# Scaling the Features - "Amount" and "Time"
from sklearn.preprocessing import RobustScaler  # Robust Scalar is less prone to outliers
rob_scaler = RobustScaler()

credit_df['Amount_Scaled'] = rob_scaler.fit_transform(credit_df['Amount'].values.reshape(-1,1))
credit_df['Time_Scaled'] = rob_scaler.fit_transform(credit_df['Time'].values.reshape(-1,1))

credit_df.drop(['Time','Amount'], axis=1, inplace=True)

Amount_Scaled = credit_df['Amount_Scaled']
Time_Scaled = credit_df['Time_Scaled']

credit_df.drop(['Amount_Scaled', 'Time_Scaled'], axis=1, inplace=True)
credit_df.insert(0, 'Amount_Scaled', Amount_Scaled)
credit_df.insert(1, 'Time_Scaled', Time_Scaled)

credit_df

"""# Under Sampling

## Random Under-Sampling

One way to handle the imbalance dataset is undersampling which we are going to perform now.

Bulid a sample dataset containing same number of Normal and Fraudulent Transactions

Number of Fraudulent Transactions = 492
"""

X_under = credit_df.drop("Class", axis="columns")
y_under = credit_df["Class"]

"""###Spliting into Train and Test Data"""

X_train_under,X_test_under,y_train_under,y_test_under = train_test_split(X_under, y_under , test_size = 0.25,random_state = 42)

from imblearn.under_sampling import RandomUnderSampler

# Undersampling method from sklearn libraby - Reduces Data
under = RandomUnderSampler(random_state = 42 )
X_train_under_resampled, y_train_under_resampled = under.fit_resample(X_train_under, y_train_under)

X_train_under_resampled

y_train_under.value_counts()

"""###Model Training

####Logistic Regression Model
"""

Logistic_Regression_under = LogisticRegression()

"""Training Dataset"""

Logistic_Regression_under.fit(X_train_under_resampled,y_train_under_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_under_logistic = Logistic_Regression_under.predict(X_train_under_resampled)
train_accuracy_under_logistic = accuracy_score(y_train_under_resampled,train_pred_under_logistic)
train_precision_under_logistic = precision_score(y_train_under_resampled,train_pred_under_logistic)
train_recall_under_logistic = recall_score(y_train_under_resampled,train_pred_under_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_under_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_under_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_under_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_under_train_logistic = pd.DataFrame(y_train_under_resampled)
pred_under_train_logistic['predicted'] = train_pred_under_logistic
pred_under_train_logistic

pred_under_train_cls0_logistic = pred_under_train_logistic[pred_under_train_logistic['Class'] == 0]
pred_under_train_cls1_logistic = pred_under_train_logistic[pred_under_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_under_class0_logistic = accuracy_score(pred_under_train_cls0_logistic['Class'],pred_under_train_cls0_logistic['predicted'])
train_precision_under_class0_logistic = precision_score(pred_under_train_cls0_logistic['Class'],pred_under_train_cls0_logistic['predicted'])
train_recall_under_class0_logistic = recall_score(pred_under_train_cls0_logistic['Class'],pred_under_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_under_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_under_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_under_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_under_class1_logistic = accuracy_score(pred_under_train_cls1_logistic['Class'],pred_under_train_cls1_logistic['predicted'])
train_precision_under_class1_logistic = precision_score(pred_under_train_cls1_logistic['Class'],pred_under_train_cls1_logistic['predicted'])
train_recall_under_class1_logistic = recall_score(pred_under_train_cls1_logistic['Class'],pred_under_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_under_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_under_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_under_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_under_logistic = Logistic_Regression_under.predict(X_test_under)
test_accuracy1_under_logistic = accuracy_score(y_test_under,test_pred_under_logistic)
test_precision1_under_logistic = precision_score(y_test_under,test_pred_under_logistic)
test_recall1_under_logistic = recall_score(y_test_under,test_pred_under_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_under_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_under_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_under_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_under_logistic = confusion_matrix(y_test_under,test_pred_under_logistic)

cm_display_under_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_under_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_under_logistic.plot()
plt.title("Confusion Matrix - Random under Sampling -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_under_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_under,X_test_under,y_test_under)

"""Class wise Accuracy"""

pred_under_test_logistic = pd.DataFrame(y_test_under)
pred_under_test_logistic['predicted'] = test_pred_under_logistic

pred_under_test_logistic

pred_under_test_cls0_logistic = pred_under_test_logistic[pred_under_test_logistic['Class'] == 0]
pred_under_test_cls1_logistic = pred_under_test_logistic[pred_under_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_under_logistic = accuracy_score(pred_under_test_cls0_logistic['Class'],pred_under_test_cls0_logistic['predicted'])
test_precision_class0_under_logistic = precision_score(pred_under_test_cls0_logistic['Class'],pred_under_test_cls0_logistic['predicted'])
test_recall_class0_under_logistic = recall_score(pred_under_test_cls0_logistic['Class'],pred_under_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_under_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_under_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_under_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_under_logistic = accuracy_score(pred_under_test_cls1_logistic['Class'],pred_under_test_cls1_logistic['predicted'])
test_precision_class1_under_logistic = precision_score(pred_under_test_cls1_logistic['Class'],pred_under_test_cls1_logistic['predicted'])
test_recall_class1_under_logistic = recall_score(pred_under_test_cls1_logistic['Class'],pred_under_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_under_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_under_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_under_logistic*100,2)," %")

"""#### Random Forest Classifier"""

Random_Forest_under = RandomForestClassifier()

"""Training Dataset"""

Random_Forest_under.fit(X_train_under_resampled,y_train_under_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_under_RF = Random_Forest_under.predict(X_train_under_resampled)
train_accuracy_under_RF = accuracy_score(y_train_under_resampled,train_pred_under_RF)
train_precision_under_RF = precision_score(y_train_under_resampled,train_pred_under_RF)
train_recall_under_RF = recall_score(y_train_under_resampled,train_pred_under_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_under_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_under_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_under_RF*100,2)," %")

"""Classwise Accuracy"""

pred_under_train_RF = pd.DataFrame(y_train_under_resampled)
pred_under_train_RF['predicted'] = train_pred_under_RF
pred_under_train_RF

pred_under_train_cls0_RF = pred_under_train_RF[pred_under_train_RF['Class'] == 0]
pred_under_train_cls1_RF = pred_under_train_RF[pred_under_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_under_class0_RF = accuracy_score(pred_under_train_cls0_RF['Class'],pred_under_train_cls0_RF['predicted'])
train_precision_under_class0_RF = precision_score(pred_under_train_cls0_RF['Class'],pred_under_train_cls0_RF['predicted'])
train_recall_under_class0_RF = recall_score(pred_under_train_cls0_RF['Class'],pred_under_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_under_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_under_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_under_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_under_class1_RF = accuracy_score(pred_under_train_cls1_RF['Class'],pred_under_train_cls1_RF['predicted'])
train_precision_under_class1_RF = precision_score(pred_under_train_cls1_RF['Class'],pred_under_train_cls1_RF['predicted'])
train_recall_under_class1_RF = recall_score(pred_under_train_cls1_RF['Class'],pred_under_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_under_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_under_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_under_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_under_RF = Random_Forest_under.predict(X_test_under)
test_accuracy1_under_RF = accuracy_score(y_test_under,test_pred_under_RF)
test_precision1_under_RF = precision_score(y_test_under,test_pred_under_RF)
test_recall1_under_RF = recall_score(y_test_under,test_pred_under_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_under_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_under_RF*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_under_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_under_RF = confusion_matrix(y_test_under,test_pred_under_RF)

cm_display_under_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_under_RF, display_labels = ['Normal', 'Fraud'])

cm_display_under_RF.plot()
plt.title("Confusion Matrix - Random under Sampling -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_under_RF = RocCurveDisplay.from_estimator(Random_Forest_under,X_test_under,y_test_under)

"""Class wise Accuracy"""

pred_under_test_RF = pd.DataFrame(y_test_under)
pred_under_test_RF['predicted'] = test_pred_under_RF

pred_under_test_RF

pred_under_test_cls0_RF = pred_under_test_RF[pred_under_test_RF['Class'] == 0]
pred_under_test_cls1_RF = pred_under_test_RF[pred_under_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_under_RF = accuracy_score(pred_under_test_cls0_RF['Class'],pred_under_test_cls0_RF['predicted'])
test_precision_class0_under_RF = precision_score(pred_under_test_cls0_RF['Class'],pred_under_test_cls0_RF['predicted'])
test_recall_class0_under_RF = recall_score(pred_under_test_cls0_RF['Class'],pred_under_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_under_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_under_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_under_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_under_RF = accuracy_score(pred_under_test_cls1_RF['Class'],pred_under_test_cls1_RF['predicted'])
test_precision_class1_under_RF = precision_score(pred_under_test_cls1_RF['Class'],pred_under_test_cls1_RF['predicted'])
test_recall_class1_under_RF = recall_score(pred_under_test_cls1_RF['Class'],pred_under_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_under_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_under_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_under_RF*100,2)," %")

"""#### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

xgb_under = xgb.XGBClassifier(objective="binary:logistic")

"""Training Dataset"""

xgb_under.fit(X_train_under_resampled,y_train_under_resampled)

"""##### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_under_xgb = xgb_under.predict(X_train_under_resampled)
train_accuracy_under_xgb = accuracy_score(y_train_under_resampled,train_pred_under_xgb)
train_precision_under_xgb = precision_score(y_train_under_resampled,train_pred_under_xgb)
train_recall_under_xgb = recall_score(y_train_under_resampled,train_pred_under_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_under_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_under_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_under_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_under_train_xgb = pd.DataFrame(y_train_under_resampled)
pred_under_train_xgb['predicted'] = train_pred_under_xgb
pred_under_train_xgb

pred_under_train_cls0_xgb = pred_under_train_xgb[pred_under_train_xgb['Class'] == 0]
pred_under_train_cls1_xgb = pred_under_train_xgb[pred_under_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_under_class0_xgb = accuracy_score(pred_under_train_cls0_xgb['Class'],pred_under_train_cls0_xgb['predicted'])
train_precision_under_class0_xgb = precision_score(pred_under_train_cls0_xgb['Class'],pred_under_train_cls0_xgb['predicted'])
train_recall_under_class0_xgb = recall_score(pred_under_train_cls0_xgb['Class'],pred_under_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_under_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_under_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_under_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_under_class1_xgb = accuracy_score(pred_under_train_cls1_xgb['Class'],pred_under_train_cls1_xgb['predicted'])
train_precision_under_class1_xgb = precision_score(pred_under_train_cls1_xgb['Class'],pred_under_train_cls1_xgb['predicted'])
train_recall_under_class1_xgb = recall_score(pred_under_train_cls1_xgb['Class'],pred_under_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_under_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_under_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_under_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_under_xgb = xgb_under.predict(X_test_under)
test_accuracy1_under_xgb = accuracy_score(y_test_under,test_pred_under_xgb)
test_precision1_under_xgb = precision_score(y_test_under,test_pred_under_xgb)
test_recall1_under_xgb = recall_score(y_test_under,test_pred_under_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_under_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_under_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_under_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_under_xgb = confusion_matrix(y_test_under,test_pred_under_xgb)

cm_display_under_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_under_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_under_xgb.plot()
plt.title("Confusion Matrix - Random under Sampling -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_under_xgb = RocCurveDisplay.from_estimator(xgb_under,X_test_under,y_test_under)

"""Class wise Accuracy"""

pred_under_test_xgb = pd.DataFrame(y_test_under)
pred_under_test_xgb['predicted'] = test_pred_under_xgb

pred_under_test_xgb

pred_under_test_cls0_xgb = pred_under_test_xgb[pred_under_test_xgb['Class'] == 0]
pred_under_test_cls1_xgb = pred_under_test_xgb[pred_under_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_under_xgb = accuracy_score(pred_under_test_cls0_xgb['Class'],pred_under_test_cls0_xgb['predicted'])
test_precision_class0_under_xgb = precision_score(pred_under_test_cls0_xgb['Class'],pred_under_test_cls0_xgb['predicted'])
test_recall_class0_under_xgb = recall_score(pred_under_test_cls0_xgb['Class'],pred_under_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_under_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_under_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_under_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_under_xgb = accuracy_score(pred_under_test_cls1_xgb['Class'],pred_under_test_cls1_xgb['predicted'])
test_precision_class1_under_xgb = precision_score(pred_under_test_cls1_xgb['Class'],pred_under_test_cls1_xgb['predicted'])
test_recall_class1_under_xgb = recall_score(pred_under_test_cls1_xgb['Class'],pred_under_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_under_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_under_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_under_xgb*100,2)," %")

"""#### Support Vector Machine Classifier




"""

svc_under = SVC()

"""Training Dataset"""

svc_under.fit(X_train_under_resampled,y_train_under_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_under_svc = svc_under.predict(X_train_under_resampled)
train_accuracy_under_svc = accuracy_score(y_train_under_resampled,train_pred_under_svc)
train_precision_under_svc = precision_score(y_train_under_resampled,train_pred_under_svc)
train_recall_under_svc = recall_score(y_train_under_resampled,train_pred_under_svc)

print("Accuracy on Training Data is: ",round(train_accuracy_under_svc*100,2)," %")
print("precision on Training Data is: ",round(train_precision_under_svc*100,2)," %")
print("recall on Training Data is: ",round(train_recall_under_svc*100,2)," %")

"""Classwise Accuracy"""

pred_under_train_svc = pd.DataFrame(y_train_under_resampled)
pred_under_train_svc['predicted'] = train_pred_under_svc
pred_under_train_svc

pred_under_train_cls0_svc = pred_under_train_svc[pred_under_train_svc['Class'] == 0]
pred_under_train_cls1_svc = pred_under_train_svc[pred_under_train_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_under_class0_svc = accuracy_score(pred_under_train_cls0_svc['Class'],pred_under_train_cls0_svc['predicted'])
train_precision_under_class0_svc = precision_score(pred_under_train_cls0_svc['Class'],pred_under_train_cls0_svc['predicted'])
train_recall_under_class0_svc = recall_score(pred_under_train_cls0_svc['Class'],pred_under_train_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_under_class0_svc*100,2)," %")
print("precision of Class 0: ",round(train_precision_under_class0_svc*100,2)," %")
print("recall of Class 0: ",round(train_recall_under_class0_svc*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_under_class1_svc = accuracy_score(pred_under_train_cls1_svc['Class'],pred_under_train_cls1_svc['predicted'])
train_precision_under_class1_svc = precision_score(pred_under_train_cls1_svc['Class'],pred_under_train_cls1_svc['predicted'])
train_recall_under_class1_svc = recall_score(pred_under_train_cls1_svc['Class'],pred_under_train_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_under_class1_svc*100,2)," %")
print("precision of Class 1: ",round(train_precision_under_class1_svc*100,2)," %")
print("recall of Class 1: ",round(train_recall_under_class1_svc*100,2)," %")

"""On Testing Data"""

test_pred_under_svc = svc_under.predict(X_test_under)
test_accuracy1_under_svc = accuracy_score(y_test_under,test_pred_under_svc)
test_precision1_under_svc = precision_score(y_test_under,test_pred_under_svc)
test_recall1_under_svc = recall_score(y_test_under,test_pred_under_svc)


print("Accuracy on Testing Data is: ",round(test_accuracy1_under_svc*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_under_svc*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_under_svc*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_under_svc = confusion_matrix(y_test_under,test_pred_under_svc)

cm_display_under_svc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_under_svc, display_labels = ['Normal', 'Fraud'])

cm_display_under_svc.plot()
plt.title("Confusion Matrix - Random under Sampling -svc- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_under_svc = RocCurveDisplay.from_estimator(svc_under,X_test_under,y_test_under)

"""Class wise Accuracy"""

pred_under_test_svc = pd.DataFrame(y_test_under)
pred_under_test_svc['predicted'] = test_pred_under_svc

pred_under_test_svc

pred_under_test_cls0_svc = pred_under_test_svc[pred_under_test_svc['Class'] == 0]
pred_under_test_cls1_svc = pred_under_test_svc[pred_under_test_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_under_svc = accuracy_score(pred_under_test_cls0_svc['Class'],pred_under_test_cls0_svc['predicted'])
test_precision_class0_under_svc = precision_score(pred_under_test_cls0_svc['Class'],pred_under_test_cls0_svc['predicted'])
test_recall_class0_under_svc = recall_score(pred_under_test_cls0_svc['Class'],pred_under_test_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_under_svc*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_under_svc*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_under_svc*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_under_svc = accuracy_score(pred_under_test_cls1_svc['Class'],pred_under_test_cls1_svc['predicted'])
test_precision_class1_under_svc = precision_score(pred_under_test_cls1_svc['Class'],pred_under_test_cls1_svc['predicted'])
test_recall_class1_under_svc = recall_score(pred_under_test_cls1_svc['Class'],pred_under_test_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_under_svc*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_under_svc*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_under_svc*100,2)," %")

"""### Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Graph"""

Acc_under_train_cls0 = [train_accuracy_under_class0_logistic,train_accuracy_under_class0_RF,train_accuracy_under_class0_xgb,train_accuracy_under_class0_svc]
Acc_under_test_cls0 = [test_accuracy_class0_under_logistic,test_accuracy_class0_under_RF,test_accuracy_class0_under_xgb,test_accuracy_class0_under_svc]
Acc_under_train_cls1 = [train_accuracy_under_class1_logistic,train_accuracy_under_class1_RF,train_accuracy_under_class1_xgb,train_accuracy_under_class1_svc]
Acc_under_test_cls1 = [test_accuracy_class1_under_logistic,test_accuracy_class1_under_RF,test_accuracy_class1_under_xgb,test_accuracy_class1_under_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_under_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_under_train_cls0)

plt.plot(Model,Acc_under_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_under_test_cls0)

plt.plot(Model,Acc_under_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_under_train_cls1)

plt.plot(Model,Acc_under_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_under_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - Random Under Sampling")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_under_train_cls0 = [train_precision_under_class0_logistic,train_precision_under_class0_RF,train_precision_under_class0_xgb,train_precision_under_class0_svc]
Pre_under_test_cls0 = [test_precision_class0_under_logistic,test_precision_class0_under_RF,test_precision_class0_under_xgb,test_precision_class0_under_svc]
Pre_under_train_cls1 = [train_precision_under_class1_logistic,train_precision_under_class1_RF,train_precision_under_class1_xgb,train_precision_under_class1_svc]
Pre_under_test_cls1 = [test_precision_class1_under_logistic,test_precision_class1_under_RF,test_precision_class1_under_xgb,test_precision_class1_under_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_under_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_under_train_cls0)

plt.plot(Model,Pre_under_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_under_test_cls0)

plt.plot(Model,Pre_under_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_under_train_cls1)

plt.plot(Model,Pre_under_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_under_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - Random Under Sampling")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_under_train_cls0 = [train_recall_under_class0_logistic,train_recall_under_class0_RF,train_recall_under_class0_xgb,train_recall_under_class0_svc]
Recall_under_test_cls0 = [test_recall_class0_under_logistic,test_recall_class0_under_RF,test_recall_class0_under_xgb,test_recall_class0_under_svc]
Recall_under_train_cls1 = [train_recall_under_class1_logistic,train_recall_under_class1_RF,train_recall_under_class1_xgb,train_recall_under_class1_svc]
Recall_under_test_cls1 = [test_recall_class1_under_logistic,test_recall_class1_under_RF,test_recall_class1_under_xgb,test_recall_class1_under_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_under_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_under_train_cls0)

plt.plot(Model,Recall_under_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_under_test_cls0)

plt.plot(Model,Recall_under_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_under_train_cls1)

plt.plot(Model,Recall_under_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_under_test_cls1)

plt.ylabel("Recall")
plt.xlabel("Model")
plt.title("Comparision of Model Recall - Random Under Sampling")
plt.legend()
plt.show()

"""## ENN - Edited Nearest Neighbours"""

X_enn = credit_df.drop("Class", axis="columns")
y_enn = credit_df["Class"]

"""###Spliting into Train and Test Data"""

X_train_enn,X_test_enn,y_train_enn,y_test_enn = train_test_split(X_enn, y_enn , test_size = 0.25,random_state = 42)

from imblearn.under_sampling import EditedNearestNeighbours

enn = EditedNearestNeighbours()
X_train_enn_resampled, y_train_enn_resampled = enn.fit_resample(X_train_enn, y_train_enn)

X_train_enn_resampled

y_train_enn.value_counts()

"""###Model Training

####Logistic Regression Model
"""

Logistic_Regression_enn = LogisticRegression()

"""Training Dataset"""

Logistic_Regression_enn.fit(X_train_enn_resampled,y_train_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_enn_logistic = Logistic_Regression_enn.predict(X_train_enn_resampled)
train_accuracy_enn_logistic = accuracy_score(y_train_enn_resampled,train_pred_enn_logistic)
train_precision_enn_logistic = precision_score(y_train_enn_resampled,train_pred_enn_logistic)
train_recall_enn_logistic = recall_score(y_train_enn_resampled,train_pred_enn_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_enn_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_enn_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_enn_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_enn_train_logistic = pd.DataFrame(y_train_enn_resampled)
pred_enn_train_logistic['predicted'] = train_pred_enn_logistic
pred_enn_train_logistic

pred_enn_train_cls0_logistic = pred_enn_train_logistic[pred_enn_train_logistic['Class'] == 0]
pred_enn_train_cls1_logistic = pred_enn_train_logistic[pred_enn_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_enn_class0_logistic = accuracy_score(pred_enn_train_cls0_logistic['Class'],pred_enn_train_cls0_logistic['predicted'])
train_precision_enn_class0_logistic = precision_score(pred_enn_train_cls0_logistic['Class'],pred_enn_train_cls0_logistic['predicted'])
train_recall_enn_class0_logistic = recall_score(pred_enn_train_cls0_logistic['Class'],pred_enn_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_enn_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_enn_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_enn_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_enn_class1_logistic = accuracy_score(pred_enn_train_cls1_logistic['Class'],pred_enn_train_cls1_logistic['predicted'])
train_precision_enn_class1_logistic = precision_score(pred_enn_train_cls1_logistic['Class'],pred_enn_train_cls1_logistic['predicted'])
train_recall_enn_class1_logistic = recall_score(pred_enn_train_cls1_logistic['Class'],pred_enn_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_enn_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_enn_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_enn_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_enn_logistic = Logistic_Regression_enn.predict(X_test_enn)
test_accuracy1_enn_logistic = accuracy_score(y_test_enn,test_pred_enn_logistic)
test_precision1_enn_logistic = precision_score(y_test_enn,test_pred_enn_logistic)
test_recall1_enn_logistic = recall_score(y_test_enn,test_pred_enn_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_enn_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_enn_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_enn_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_enn_logistic = confusion_matrix(y_test_enn,test_pred_enn_logistic)

cm_display_enn_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_enn_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_enn_logistic.plot()
plt.title("Confusion Matrix - ENN Sampling -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_enn_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_enn,X_test_enn,y_test_enn)

"""Class wise Accuracy"""

pred_enn_test_logistic = pd.DataFrame(y_test_enn)
pred_enn_test_logistic['predicted'] = test_pred_enn_logistic

pred_enn_test_logistic

pred_enn_test_cls0_logistic = pred_enn_test_logistic[pred_enn_test_logistic['Class'] == 0]
pred_enn_test_cls1_logistic = pred_enn_test_logistic[pred_enn_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_enn_logistic = accuracy_score(pred_enn_test_cls0_logistic['Class'],pred_enn_test_cls0_logistic['predicted'])
test_precision_class0_enn_logistic = precision_score(pred_enn_test_cls0_logistic['Class'],pred_enn_test_cls0_logistic['predicted'])
test_recall_class0_enn_logistic = recall_score(pred_enn_test_cls0_logistic['Class'],pred_enn_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_enn_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_enn_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_enn_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_enn_logistic = accuracy_score(pred_enn_test_cls1_logistic['Class'],pred_enn_test_cls1_logistic['predicted'])
test_precision_class1_enn_logistic = precision_score(pred_enn_test_cls1_logistic['Class'],pred_enn_test_cls1_logistic['predicted'])
test_recall_class1_enn_logistic = recall_score(pred_enn_test_cls1_logistic['Class'],pred_enn_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_enn_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_enn_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_enn_logistic*100,2)," %")

"""#### Random Forest Classifier"""

Random_Forest_enn = RandomForestClassifier()

"""Training Dataset"""

Random_Forest_enn.fit(X_train_enn_resampled,y_train_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_enn_RF = Random_Forest_enn.predict(X_train_enn_resampled)
train_accuracy_enn_RF = accuracy_score(y_train_enn_resampled,train_pred_enn_RF)
train_precision_enn_RF = precision_score(y_train_enn_resampled,train_pred_enn_RF)
train_recall_enn_RF = recall_score(y_train_enn_resampled,train_pred_enn_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_enn_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_enn_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_enn_RF*100,2)," %")

"""Classwise Accuracy"""

pred_enn_train_RF = pd.DataFrame(y_train_enn_resampled)
pred_enn_train_RF['predicted'] = train_pred_enn_RF
pred_enn_train_RF

pred_enn_train_cls0_RF = pred_enn_train_RF[pred_enn_train_RF['Class'] == 0]
pred_enn_train_cls1_RF = pred_enn_train_RF[pred_enn_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_enn_class0_RF = accuracy_score(pred_enn_train_cls0_RF['Class'],pred_enn_train_cls0_RF['predicted'])
train_precision_enn_class0_RF = precision_score(pred_enn_train_cls0_RF['Class'],pred_enn_train_cls0_RF['predicted'])
train_recall_enn_class0_RF = recall_score(pred_enn_train_cls0_RF['Class'],pred_enn_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_enn_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_enn_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_enn_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_enn_class1_RF = accuracy_score(pred_enn_train_cls1_RF['Class'],pred_enn_train_cls1_RF['predicted'])
train_precision_enn_class1_RF = precision_score(pred_enn_train_cls1_RF['Class'],pred_enn_train_cls1_RF['predicted'])
train_recall_enn_class1_RF = recall_score(pred_enn_train_cls1_RF['Class'],pred_enn_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_enn_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_enn_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_enn_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_enn_RF = Random_Forest_enn.predict(X_test_enn)
test_accuracy1_enn_RF = accuracy_score(y_test_enn,test_pred_enn_RF)
test_precision1_enn_RF = precision_score(y_test_enn,test_pred_enn_RF)
test_recall1_enn_RF = recall_score(y_test_enn,test_pred_enn_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_enn_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_enn_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_enn_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_enn_RF = confusion_matrix(y_test_enn,test_pred_enn_RF)

cm_display_enn_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_enn_RF, display_labels = ['Normal', 'Fraud'])

cm_display_enn_RF.plot()
plt.title("Confusion Matrix - ENN Sampling -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_enn_RF = RocCurveDisplay.from_estimator(Random_Forest_enn,X_test_enn,y_test_enn)

"""Class wise Accuracy"""

pred_enn_test_RF = pd.DataFrame(y_test_enn)
pred_enn_test_RF['predicted'] = test_pred_enn_RF

pred_enn_test_RF

pred_enn_test_cls0_RF = pred_enn_test_RF[pred_enn_test_RF['Class'] == 0]
pred_enn_test_cls1_RF = pred_enn_test_RF[pred_enn_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_enn_RF = accuracy_score(pred_enn_test_cls0_RF['Class'],pred_enn_test_cls0_RF['predicted'])
test_precision_class0_enn_RF = precision_score(pred_enn_test_cls0_RF['Class'],pred_enn_test_cls0_RF['predicted'])
test_recall_class0_enn_RF = recall_score(pred_enn_test_cls0_RF['Class'],pred_enn_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_enn_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_enn_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_enn_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_enn_RF = accuracy_score(pred_enn_test_cls1_RF['Class'],pred_enn_test_cls1_RF['predicted'])
test_precision_class1_enn_RF = precision_score(pred_enn_test_cls1_RF['Class'],pred_enn_test_cls1_RF['predicted'])
test_recall_class1_enn_RF = recall_score(pred_enn_test_cls1_RF['Class'],pred_enn_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_enn_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_enn_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_enn_RF*100,2)," %")

"""#### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

xgb_enn = xgb.XGBClassifier(objective="binary:logistic")

"""Training Dataset"""

xgb_enn.fit(X_train_enn_resampled,y_train_enn_resampled)

"""##### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_enn_xgb = xgb_enn.predict(X_train_enn_resampled)
train_accuracy_enn_xgb = accuracy_score(y_train_enn_resampled,train_pred_enn_xgb)
train_precision_enn_xgb = precision_score(y_train_enn_resampled,train_pred_enn_xgb)
train_recall_enn_xgb = recall_score(y_train_enn_resampled,train_pred_enn_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_enn_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_enn_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_enn_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_enn_train_xgb = pd.DataFrame(y_train_enn_resampled)
pred_enn_train_xgb['predicted'] = train_pred_enn_xgb
pred_enn_train_xgb

pred_enn_train_cls0_xgb = pred_enn_train_xgb[pred_enn_train_xgb['Class'] == 0]
pred_enn_train_cls1_xgb = pred_enn_train_xgb[pred_enn_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_enn_class0_xgb = accuracy_score(pred_enn_train_cls0_xgb['Class'],pred_enn_train_cls0_xgb['predicted'])
train_precision_enn_class0_xgb = precision_score(pred_enn_train_cls0_xgb['Class'],pred_enn_train_cls0_xgb['predicted'])
train_recall_enn_class0_xgb = recall_score(pred_enn_train_cls0_xgb['Class'],pred_enn_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_enn_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_enn_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_enn_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_enn_class1_xgb = accuracy_score(pred_enn_train_cls1_xgb['Class'],pred_enn_train_cls1_xgb['predicted'])
train_precision_enn_class1_xgb = precision_score(pred_enn_train_cls1_xgb['Class'],pred_enn_train_cls1_xgb['predicted'])
train_recall_enn_class1_xgb = recall_score(pred_enn_train_cls1_xgb['Class'],pred_enn_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_enn_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_enn_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_enn_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_enn_xgb = xgb_enn.predict(X_test_enn)
test_accuracy1_enn_xgb = accuracy_score(y_test_enn,test_pred_enn_xgb)
test_precision1_enn_xgb = precision_score(y_test_enn,test_pred_enn_xgb)
test_recall1_enn_xgb = recall_score(y_test_enn,test_pred_enn_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_enn_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_enn_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_enn_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_enn_xgb = confusion_matrix(y_test_enn,test_pred_enn_xgb)

cm_display_enn_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_enn_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_enn_xgb.plot()
plt.title("Confusion Matrix - ENN Sampling -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_enn_xgb = RocCurveDisplay.from_estimator(xgb_enn,X_test_enn,y_test_enn)

"""Class wise Accuracy"""

pred_enn_test_xgb = pd.DataFrame(y_test_enn)
pred_enn_test_xgb['predicted'] = test_pred_enn_xgb

pred_enn_test_xgb

pred_enn_test_cls0_xgb = pred_enn_test_xgb[pred_enn_test_xgb['Class'] == 0]
pred_enn_test_cls1_xgb = pred_enn_test_xgb[pred_enn_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_enn_xgb = accuracy_score(pred_enn_test_cls0_xgb['Class'],pred_enn_test_cls0_xgb['predicted'])
test_precision_class0_enn_xgb = precision_score(pred_enn_test_cls0_xgb['Class'],pred_enn_test_cls0_xgb['predicted'])
test_recall_class0_enn_xgb = recall_score(pred_enn_test_cls0_xgb['Class'],pred_enn_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_enn_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_enn_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_enn_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_enn_xgb = accuracy_score(pred_enn_test_cls1_xgb['Class'],pred_enn_test_cls1_xgb['predicted'])
test_precision_class1_enn_xgb = precision_score(pred_enn_test_cls1_xgb['Class'],pred_enn_test_cls1_xgb['predicted'])
test_recall_class1_enn_xgb = recall_score(pred_enn_test_cls1_xgb['Class'],pred_enn_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_enn_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_enn_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_enn_xgb*100,2)," %")

"""#### Support Vector Machine Classifier




"""

svc_enn = SVC()

"""Training Dataset"""

svc_enn.fit(X_train_enn_resampled,y_train_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_enn_svc = svc_enn.predict(X_train_enn_resampled)
train_accuracy_enn_svc = accuracy_score(y_train_enn_resampled,train_pred_enn_svc)
train_precision_enn_svc = precision_score(y_train_enn_resampled,train_pred_enn_svc)
train_recall_enn_svc = recall_score(y_train_enn_resampled,train_pred_enn_svc)

print("Accuracy on Training Data is: ",round(train_accuracy_enn_svc*100,2)," %")
print("precision on Training Data is: ",round(train_precision_enn_svc*100,2)," %")
print("recall on Training Data is: ",round(train_recall_enn_svc*100,2)," %")

"""Classwise Accuracy"""

pred_enn_train_svc = pd.DataFrame(y_train_enn_resampled)
pred_enn_train_svc['predicted'] = train_pred_enn_svc
pred_enn_train_svc

pred_enn_train_cls0_svc = pred_enn_train_svc[pred_enn_train_svc['Class'] == 0]
pred_enn_train_cls1_svc = pred_enn_train_svc[pred_enn_train_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_enn_class0_svc = accuracy_score(pred_enn_train_cls0_svc['Class'],pred_enn_train_cls0_svc['predicted'])
train_precision_enn_class0_svc = precision_score(pred_enn_train_cls0_svc['Class'],pred_enn_train_cls0_svc['predicted'])
train_recall_enn_class0_svc = recall_score(pred_enn_train_cls0_svc['Class'],pred_enn_train_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_enn_class0_svc*100,2)," %")
print("precision of Class 0: ",round(train_precision_enn_class0_svc*100,2)," %")
print("recall of Class 0: ",round(train_recall_enn_class0_svc*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_enn_class1_svc = accuracy_score(pred_enn_train_cls1_svc['Class'],pred_enn_train_cls1_svc['predicted'])
train_precision_enn_class1_svc = precision_score(pred_enn_train_cls1_svc['Class'],pred_enn_train_cls1_svc['predicted'])
train_recall_enn_class1_svc = recall_score(pred_enn_train_cls1_svc['Class'],pred_enn_train_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_enn_class1_svc*100,2)," %")
print("precision of Class 1: ",round(train_precision_enn_class1_svc*100,2)," %")
print("recall of Class 1: ",round(train_recall_enn_class1_svc*100,2)," %")

"""On Testing Data"""

test_pred_enn_svc = svc_enn.predict(X_test_enn)
test_accuracy1_enn_svc = accuracy_score(y_test_enn,test_pred_enn_svc)
test_precision1_enn_svc = precision_score(y_test_enn,test_pred_enn_svc)
test_recall1_enn_svc = recall_score(y_test_enn,test_pred_enn_svc)


print("Accuracy on Testing Data is: ",round(test_accuracy1_enn_svc*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_enn_svc*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_enn_svc*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_enn_svc = confusion_matrix(y_test_enn,test_pred_enn_svc)

cm_display_enn_svc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_enn_svc, display_labels = ['Normal', 'Fraud'])

cm_display_enn_svc.plot()
plt.title("Confusion Matrix - ENN Sampling -svc- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_enn_svc = RocCurveDisplay.from_estimator(svc_enn,X_test_enn,y_test_enn)

"""Class wise Accuracy"""

pred_enn_test_svc = pd.DataFrame(y_test_enn)
pred_enn_test_svc['predicted'] = test_pred_enn_svc

pred_enn_test_svc

pred_enn_test_cls0_svc = pred_enn_test_svc[pred_enn_test_svc['Class'] == 0]
pred_enn_test_cls1_svc = pred_enn_test_svc[pred_enn_test_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_enn_svc = accuracy_score(pred_enn_test_cls0_svc['Class'],pred_enn_test_cls0_svc['predicted'])
test_precision_class0_enn_svc = precision_score(pred_enn_test_cls0_svc['Class'],pred_enn_test_cls0_svc['predicted'])
test_recall_class0_enn_svc = recall_score(pred_enn_test_cls0_svc['Class'],pred_enn_test_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_enn_svc*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_enn_svc*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_enn_svc*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_enn_svc = accuracy_score(pred_enn_test_cls1_svc['Class'],pred_enn_test_cls1_svc['predicted'])
test_precision_class1_enn_svc = precision_score(pred_enn_test_cls1_svc['Class'],pred_enn_test_cls1_svc['predicted'])
test_recall_class1_enn_svc = recall_score(pred_enn_test_cls1_svc['Class'],pred_enn_test_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_enn_svc*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_enn_svc*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_enn_svc*100,2)," %")

"""### Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Graph"""

Acc_enn_train_cls0 = [train_accuracy_enn_class0_logistic,train_accuracy_enn_class0_RF,train_accuracy_enn_class0_xgb,train_accuracy_enn_class0_svc]
Acc_enn_test_cls0 = [test_accuracy_class0_enn_logistic,test_accuracy_class0_enn_RF,test_accuracy_class0_enn_xgb,test_accuracy_class0_enn_svc]
Acc_enn_train_cls1 = [train_accuracy_enn_class1_logistic,train_accuracy_enn_class1_RF,train_accuracy_enn_class1_xgb,train_accuracy_enn_class1_svc]
Acc_enn_test_cls1 = [test_accuracy_class1_enn_logistic,test_accuracy_class1_enn_RF,test_accuracy_class1_enn_xgb,test_accuracy_class1_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_enn_train_cls0)

plt.plot(Model,Acc_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_enn_test_cls0)

plt.plot(Model,Acc_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_enn_train_cls1)

plt.plot(Model,Acc_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_enn_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - ENN")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_enn_train_cls0 = [train_precision_enn_class0_logistic,train_precision_enn_class0_RF,train_precision_enn_class0_xgb,train_precision_enn_class0_svc]
Pre_enn_test_cls0 = [test_precision_class0_enn_logistic,test_precision_class0_enn_RF,test_precision_class0_enn_xgb,test_precision_class0_enn_svc]
Pre_enn_train_cls1 = [train_precision_enn_class1_logistic,train_precision_enn_class1_RF,train_precision_enn_class1_xgb,train_precision_enn_class1_svc]
Pre_enn_test_cls1 = [test_precision_class1_enn_logistic,test_precision_class1_enn_RF,test_precision_class1_enn_xgb,test_precision_class1_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_enn_train_cls0)

plt.plot(Model,Pre_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_enn_test_cls0)

plt.plot(Model,Pre_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_enn_train_cls1)

plt.plot(Model,Pre_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_enn_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - ENN")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_enn_train_cls0 = [train_recall_enn_class0_logistic,train_recall_enn_class0_RF,train_recall_enn_class0_xgb,train_recall_enn_class0_svc]
Recall_enn_test_cls0 = [test_recall_class0_enn_logistic,test_recall_class0_enn_RF,test_recall_class0_enn_xgb,test_recall_class0_enn_svc]
Recall_enn_train_cls1 = [train_recall_enn_class1_logistic,train_recall_enn_class1_RF,train_recall_enn_class1_xgb,train_recall_enn_class1_svc]
Recall_enn_test_cls1 = [test_recall_class1_enn_logistic,test_recall_class1_enn_RF,test_recall_class1_enn_xgb,test_recall_class1_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_enn_train_cls0)

plt.plot(Model,Recall_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_enn_test_cls0)

plt.plot(Model,Recall_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_enn_train_cls1)

plt.plot(Model,Recall_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_enn_test_cls1)

plt.ylabel("Recall")
plt.xlabel("Model")
plt.title("Comparision of Model Recall - ENN")
plt.legend()
plt.show()

"""# Over Sampling

## Random Over-Sampling
"""

X_over = credit_df.drop("Class", axis="columns")
y_over = credit_df["Class"]

"""###Spliting into Train and Test Data"""

X_train_over,X_test_over,y_train_over,y_test_over = train_test_split(X_over, y_over , test_size = 0.25,random_state = 42)

from imblearn.over_sampling import RandomOverSampler

over = RandomOverSampler(random_state = 42 )
X_train_over_resampled, y_train_over_resampled = over.fit_resample(X_train_over, y_train_over)

X_train_over_resampled

y_train_over.value_counts()

"""###Model Training

####Logistic Regression Model
"""

Logistic_Regression_over = LogisticRegression()

"""Training Dataset"""

Logistic_Regression_over.fit(X_train_over_resampled,y_train_over_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_over_logistic = Logistic_Regression_over.predict(X_train_over_resampled)
train_accuracy_over_logistic = accuracy_score(y_train_over_resampled,train_pred_over_logistic)
train_precision_over_logistic = precision_score(y_train_over_resampled,train_pred_over_logistic)
train_recall_over_logistic = recall_score(y_train_over_resampled,train_pred_over_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_over_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_over_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_over_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_over_train_logistic = pd.DataFrame(y_train_over_resampled)
pred_over_train_logistic['predicted'] = train_pred_over_logistic
pred_over_train_logistic

pred_over_train_cls0_logistic = pred_over_train_logistic[pred_over_train_logistic['Class'] == 0]
pred_over_train_cls1_logistic = pred_over_train_logistic[pred_over_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_over_class0_logistic = accuracy_score(pred_over_train_cls0_logistic['Class'],pred_over_train_cls0_logistic['predicted'])
train_precision_over_class0_logistic = precision_score(pred_over_train_cls0_logistic['Class'],pred_over_train_cls0_logistic['predicted'])
train_recall_over_class0_logistic = recall_score(pred_over_train_cls0_logistic['Class'],pred_over_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_over_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_over_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_over_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_over_class1_logistic = accuracy_score(pred_over_train_cls1_logistic['Class'],pred_over_train_cls1_logistic['predicted'])
train_precision_over_class1_logistic = precision_score(pred_over_train_cls1_logistic['Class'],pred_over_train_cls1_logistic['predicted'])
train_recall_over_class1_logistic = recall_score(pred_over_train_cls1_logistic['Class'],pred_over_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_over_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_over_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_over_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_over_logistic = Logistic_Regression_over.predict(X_test_over)
test_accuracy1_over_logistic = accuracy_score(y_test_over,test_pred_over_logistic)
test_precision1_over_logistic = precision_score(y_test_over,test_pred_over_logistic)
test_recall1_over_logistic = recall_score(y_test_over,test_pred_over_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_over_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_over_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_over_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_over_logistic = confusion_matrix(y_test_over,test_pred_over_logistic)

cm_display_over_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_over_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_over_logistic.plot()
plt.title("Confusion Matrix - Random over Sampling -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_over_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_over,X_test_over,y_test_over)

"""Class wise Accuracy"""

pred_over_test_logistic = pd.DataFrame(y_test_over)
pred_over_test_logistic['predicted'] = test_pred_over_logistic

pred_over_test_logistic

pred_over_test_cls0_logistic = pred_over_test_logistic[pred_over_test_logistic['Class'] == 0]
pred_over_test_cls1_logistic = pred_over_test_logistic[pred_over_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_over_logistic = accuracy_score(pred_over_test_cls0_logistic['Class'],pred_over_test_cls0_logistic['predicted'])
test_precision_class0_over_logistic = precision_score(pred_over_test_cls0_logistic['Class'],pred_over_test_cls0_logistic['predicted'])
test_recall_class0_over_logistic = recall_score(pred_over_test_cls0_logistic['Class'],pred_over_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_over_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_over_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_over_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_over_logistic = accuracy_score(pred_over_test_cls1_logistic['Class'],pred_over_test_cls1_logistic['predicted'])
test_precision_class1_over_logistic = precision_score(pred_over_test_cls1_logistic['Class'],pred_over_test_cls1_logistic['predicted'])
test_recall_class1_over_logistic = recall_score(pred_over_test_cls1_logistic['Class'],pred_over_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_over_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_over_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_over_logistic*100,2)," %")

"""#### Random Forest Classifier"""

Random_Forest_over = RandomForestClassifier()

"""Training Dataset"""

Random_Forest_over.fit(X_train_over_resampled,y_train_over_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_over_RF = Random_Forest_over.predict(X_train_over_resampled)
train_accuracy_over_RF = accuracy_score(y_train_over_resampled,train_pred_over_RF)
train_precision_over_RF = precision_score(y_train_over_resampled,train_pred_over_RF)
train_recall_over_RF = recall_score(y_train_over_resampled,train_pred_over_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_over_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_over_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_over_RF*100,2)," %")

"""Classwise Accuracy"""

pred_over_train_RF = pd.DataFrame(y_train_over_resampled)
pred_over_train_RF['predicted'] = train_pred_over_RF
pred_over_train_RF

pred_over_train_cls0_RF = pred_over_train_RF[pred_over_train_RF['Class'] == 0]
pred_over_train_cls1_RF = pred_over_train_RF[pred_over_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_over_class0_RF = accuracy_score(pred_over_train_cls0_RF['Class'],pred_over_train_cls0_RF['predicted'])
train_precision_over_class0_RF = precision_score(pred_over_train_cls0_RF['Class'],pred_over_train_cls0_RF['predicted'])
train_recall_over_class0_RF = recall_score(pred_over_train_cls0_RF['Class'],pred_over_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_over_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_over_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_over_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_over_class1_RF = accuracy_score(pred_over_train_cls1_RF['Class'],pred_over_train_cls1_RF['predicted'])
train_precision_over_class1_RF = precision_score(pred_over_train_cls1_RF['Class'],pred_over_train_cls1_RF['predicted'])
train_recall_over_class1_RF = recall_score(pred_over_train_cls1_RF['Class'],pred_over_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_over_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_over_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_over_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_over_RF = Random_Forest_over.predict(X_test_over)
test_accuracy1_over_RF = accuracy_score(y_test_over,test_pred_over_RF)
test_precision1_over_RF = precision_score(y_test_over,test_pred_over_RF)
test_recall1_over_RF = recall_score(y_test_over,test_pred_over_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_over_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_over_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_over_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_over_RF = confusion_matrix(y_test_over,test_pred_over_RF)

cm_display_over_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_over_RF, display_labels = ['Normal', 'Fraud'])

cm_display_over_RF.plot()
plt.title("Confusion Matrix - Random over Sampling -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_over_RF = RocCurveDisplay.from_estimator(Random_Forest_over,X_test_over,y_test_over)

"""Class wise Accuracy"""

pred_over_test_RF = pd.DataFrame(y_test_over)
pred_over_test_RF['predicted'] = test_pred_over_RF

pred_over_test_RF

pred_over_test_cls0_RF = pred_over_test_RF[pred_over_test_RF['Class'] == 0]
pred_over_test_cls1_RF = pred_over_test_RF[pred_over_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_over_RF = accuracy_score(pred_over_test_cls0_RF['Class'],pred_over_test_cls0_RF['predicted'])
test_precision_class0_over_RF = precision_score(pred_over_test_cls0_RF['Class'],pred_over_test_cls0_RF['predicted'])
test_recall_class0_over_RF = recall_score(pred_over_test_cls0_RF['Class'],pred_over_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_over_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_over_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_over_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_over_RF = accuracy_score(pred_over_test_cls1_RF['Class'],pred_over_test_cls1_RF['predicted'])
test_precision_class1_over_RF = precision_score(pred_over_test_cls1_RF['Class'],pred_over_test_cls1_RF['predicted'])
test_recall_class1_over_RF = recall_score(pred_over_test_cls1_RF['Class'],pred_over_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_over_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_over_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_over_RF*100,2)," %")

"""#### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

xgb_over = xgb.XGBClassifier(objective="binary:logistic")

"""Training Dataset"""

xgb_over.fit(X_train_over_resampled,y_train_over_resampled)

"""##### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_over_xgb = xgb_over.predict(X_train_over_resampled)
train_accuracy_over_xgb = accuracy_score(y_train_over_resampled,train_pred_over_xgb)
train_precision_over_xgb = precision_score(y_train_over_resampled,train_pred_over_xgb)
train_recall_over_xgb = recall_score(y_train_over_resampled,train_pred_over_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_over_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_over_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_over_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_over_train_xgb = pd.DataFrame(y_train_over_resampled)
pred_over_train_xgb['predicted'] = train_pred_over_xgb
pred_over_train_xgb

pred_over_train_cls0_xgb = pred_over_train_xgb[pred_over_train_xgb['Class'] == 0]
pred_over_train_cls1_xgb = pred_over_train_xgb[pred_over_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_over_class0_xgb = accuracy_score(pred_over_train_cls0_xgb['Class'],pred_over_train_cls0_xgb['predicted'])
train_precision_over_class0_xgb = precision_score(pred_over_train_cls0_xgb['Class'],pred_over_train_cls0_xgb['predicted'])
train_recall_over_class0_xgb = recall_score(pred_over_train_cls0_xgb['Class'],pred_over_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_over_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_over_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_over_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_over_class1_xgb = accuracy_score(pred_over_train_cls1_xgb['Class'],pred_over_train_cls1_xgb['predicted'])
train_precision_over_class1_xgb = precision_score(pred_over_train_cls1_xgb['Class'],pred_over_train_cls1_xgb['predicted'])
train_recall_over_class1_xgb = recall_score(pred_over_train_cls1_xgb['Class'],pred_over_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_over_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_over_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_over_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_over_xgb = xgb_over.predict(X_test_over)
test_accuracy1_over_xgb = accuracy_score(y_test_over,test_pred_over_xgb)
test_precision1_over_xgb = precision_score(y_test_over,test_pred_over_xgb)
test_recall1_over_xgb = recall_score(y_test_over,test_pred_over_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_over_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_over_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_over_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_over_xgb = confusion_matrix(y_test_over,test_pred_over_xgb)

cm_display_over_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_over_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_over_xgb.plot()
plt.title("Confusion Matrix - Random over Sampling -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_over_xgb = RocCurveDisplay.from_estimator(xgb_over,X_test_over,y_test_over)

"""Class wise Accuracy"""

pred_over_test_xgb = pd.DataFrame(y_test_over)
pred_over_test_xgb['predicted'] = test_pred_over_xgb

pred_over_test_xgb

pred_over_test_cls0_xgb = pred_over_test_xgb[pred_over_test_xgb['Class'] == 0]
pred_over_test_cls1_xgb = pred_over_test_xgb[pred_over_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_over_xgb = accuracy_score(pred_over_test_cls0_xgb['Class'],pred_over_test_cls0_xgb['predicted'])
test_precision_class0_over_xgb = precision_score(pred_over_test_cls0_xgb['Class'],pred_over_test_cls0_xgb['predicted'])
test_recall_class0_over_xgb = recall_score(pred_over_test_cls0_xgb['Class'],pred_over_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_over_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_over_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_over_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_over_xgb = accuracy_score(pred_over_test_cls1_xgb['Class'],pred_over_test_cls1_xgb['predicted'])
test_precision_class1_over_xgb = precision_score(pred_over_test_cls1_xgb['Class'],pred_over_test_cls1_xgb['predicted'])
test_recall_class1_over_xgb = recall_score(pred_over_test_cls1_xgb['Class'],pred_over_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_over_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_over_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_over_xgb*100,2)," %")

"""#### Support Vector Machine Classifier




"""

svc_over = SVC()

"""Training Dataset"""

svc_over.fit(X_train_over_resampled,y_train_over_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_over_svc = svc_over.predict(X_train_over_resampled)
train_accuracy_over_svc = accuracy_score(y_train_over_resampled,train_pred_over_svc)
train_precision_over_svc = precision_score(y_train_over_resampled,train_pred_over_svc)
train_recall_over_svc = recall_score(y_train_over_resampled,train_pred_over_svc)

print("Accuracy on Training Data is: ",round(train_accuracy_over_svc*100,2)," %")
print("precision on Training Data is: ",round(train_precision_over_svc*100,2)," %")
print("recall on Training Data is: ",round(train_recall_over_svc*100,2)," %")

"""Classwise Accuracy"""

pred_over_train_svc = pd.DataFrame(y_train_over_resampled)
pred_over_train_svc['predicted'] = train_pred_over_svc
pred_over_train_svc

pred_over_train_cls0_svc = pred_over_train_svc[pred_over_train_svc['Class'] == 0]
pred_over_train_cls1_svc = pred_over_train_svc[pred_over_train_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_over_class0_svc = accuracy_score(pred_over_train_cls0_svc['Class'],pred_over_train_cls0_svc['predicted'])
train_precision_over_class0_svc = precision_score(pred_over_train_cls0_svc['Class'],pred_over_train_cls0_svc['predicted'])
train_recall_over_class0_svc = recall_score(pred_over_train_cls0_svc['Class'],pred_over_train_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_over_class0_svc*100,2)," %")
print("precision of Class 0: ",round(train_precision_over_class0_svc*100,2)," %")
print("recall of Class 0: ",round(train_recall_over_class0_svc*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_over_class1_svc = accuracy_score(pred_over_train_cls1_svc['Class'],pred_over_train_cls1_svc['predicted'])
train_precision_over_class1_svc = precision_score(pred_over_train_cls1_svc['Class'],pred_over_train_cls1_svc['predicted'])
train_recall_over_class1_svc = recall_score(pred_over_train_cls1_svc['Class'],pred_over_train_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_over_class1_svc*100,2)," %")
print("precision of Class 1: ",round(train_precision_over_class1_svc*100,2)," %")
print("recall of Class 1: ",round(train_recall_over_class1_svc*100,2)," %")

"""On Testing Data"""

test_pred_over_svc = svc_over.predict(X_test_over)
test_accuracy1_over_svc = accuracy_score(y_test_over,test_pred_over_svc)
test_precision1_over_svc = precision_score(y_test_over,test_pred_over_svc)
test_recall1_over_svc = recall_score(y_test_over,test_pred_over_svc)


print("Accuracy on Testing Data is: ",round(test_accuracy1_over_svc*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_over_svc*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_over_svc*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_over_svc = confusion_matrix(y_test_over,test_pred_over_svc)

cm_display_over_svc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_over_svc, display_labels = ['Normal', 'Fraud'])

cm_display_over_svc.plot()
plt.title("Confusion Matrix - Random over Sampling -svc- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_over_svc = RocCurveDisplay.from_estimator(svc_over,X_test_over,y_test_over)

"""Class wise Accuracy"""

pred_over_test_svc = pd.DataFrame(y_test_over)
pred_over_test_svc['predicted'] = test_pred_over_svc

pred_over_test_svc

pred_over_test_cls0_svc = pred_over_test_svc[pred_over_test_svc['Class'] == 0]
pred_over_test_cls1_svc = pred_over_test_svc[pred_over_test_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_over_svc = accuracy_score(pred_over_test_cls0_svc['Class'],pred_over_test_cls0_svc['predicted'])
test_precision_class0_over_svc = precision_score(pred_over_test_cls0_svc['Class'],pred_over_test_cls0_svc['predicted'])
test_recall_class0_over_svc = recall_score(pred_over_test_cls0_svc['Class'],pred_over_test_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_over_svc*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_over_svc*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_over_svc*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_over_svc = accuracy_score(pred_over_test_cls1_svc['Class'],pred_over_test_cls1_svc['predicted'])
test_precision_class1_over_svc = precision_score(pred_over_test_cls1_svc['Class'],pred_over_test_cls1_svc['predicted'])
test_recall_class1_over_svc = recall_score(pred_over_test_cls1_svc['Class'],pred_over_test_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_over_svc*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_over_svc*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_over_svc*100,2)," %")

"""### Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Graph"""

Acc_over_train_cls0 = [train_accuracy_over_class0_logistic,train_accuracy_over_class0_RF,train_accuracy_over_class0_xgb,train_accuracy_over_class0_svc]
Acc_over_test_cls0 = [test_accuracy_class0_over_logistic,test_accuracy_class0_over_RF,test_accuracy_class0_over_xgb,test_accuracy_class0_over_svc]
Acc_over_train_cls1 = [train_accuracy_over_class1_logistic,train_accuracy_over_class1_RF,train_accuracy_over_class1_xgb,train_accuracy_over_class1_svc]
Acc_over_test_cls1 = [test_accuracy_class1_over_logistic,test_accuracy_class1_over_RF,test_accuracy_class1_over_xgb,test_accuracy_class1_over_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_over_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_over_train_cls0)

plt.plot(Model,Acc_over_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_over_test_cls0)

plt.plot(Model,Acc_over_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_over_train_cls1)

plt.plot(Model,Acc_over_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_over_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - Random Over Sampling")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_over_train_cls0 = [train_precision_over_class0_logistic,train_precision_over_class0_RF,train_precision_over_class0_xgb,train_precision_over_class0_svc]
Pre_over_test_cls0 = [test_precision_class0_over_logistic,test_precision_class0_over_RF,test_precision_class0_over_xgb,test_precision_class0_over_svc]
Pre_over_train_cls1 = [train_precision_over_class1_logistic,train_precision_over_class1_RF,train_precision_over_class1_xgb,train_precision_over_class1_svc]
Pre_over_test_cls1 = [test_precision_class1_over_logistic,test_precision_class1_over_RF,test_precision_class1_over_xgb,test_precision_class1_over_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_over_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_over_train_cls0)

plt.plot(Model,Pre_over_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_over_test_cls0)

plt.plot(Model,Pre_over_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_over_train_cls1)

plt.plot(Model,Pre_over_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_over_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - Random Over Sampling")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_over_train_cls0 = [train_recall_over_class0_logistic,train_recall_over_class0_RF,train_recall_over_class0_xgb,train_recall_over_class0_svc]
Recall_over_test_cls0 = [test_recall_class0_over_logistic,test_recall_class0_over_RF,test_recall_class0_over_xgb,test_recall_class0_over_svc]
Recall_over_train_cls1 = [train_recall_over_class1_logistic,train_recall_over_class1_RF,train_recall_over_class1_xgb,train_recall_over_class1_svc]
Recall_over_test_cls1 = [test_recall_class1_over_logistic,test_recall_class1_over_RF,test_recall_class1_over_xgb,test_recall_class1_over_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_over_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_over_train_cls0)

plt.plot(Model,Recall_over_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_over_test_cls0)

plt.plot(Model,Recall_over_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_over_train_cls1)

plt.plot(Model,Recall_over_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_over_test_cls1)

plt.ylabel("Recall")
plt.xlabel("Model")
plt.title("Comparision of Model Recall - Random Over Sampling")
plt.legend()
plt.show()

"""## SMOTE - Synthetic Minority Over-sampling Technique"""

X_smote = credit_df.drop("Class", axis="columns")
y_smote = credit_df["Class"]

"""###Spliting into Train and Test Data"""

X_train_smote,X_test_smote,y_train_smote,y_test_smote = train_test_split(X_smote, y_smote , test_size = 0.25,random_state = 42)

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state = 42 )
X_train_smote_resampled, y_train_smote_resampled = smote.fit_resample(X_train_smote, y_train_smote)

X_train_smote_resampled

y_train_smote.value_counts()

"""###Model Training

####Logistic Regression Model
"""

Logistic_Regression_smote = LogisticRegression()

"""Training Dataset"""

Logistic_Regression_smote.fit(X_train_smote_resampled,y_train_smote_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_logistic = Logistic_Regression_smote.predict(X_train_smote_resampled)
train_accuracy_smote_logistic = accuracy_score(y_train_smote_resampled,train_pred_smote_logistic)
train_precision_smote_logistic = precision_score(y_train_smote_resampled,train_pred_smote_logistic)
train_recall_smote_logistic = recall_score(y_train_smote_resampled,train_pred_smote_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_smote_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_smote_train_logistic = pd.DataFrame(y_train_smote_resampled)
pred_smote_train_logistic['predicted'] = train_pred_smote_logistic
pred_smote_train_logistic

pred_smote_train_cls0_logistic = pred_smote_train_logistic[pred_smote_train_logistic['Class'] == 0]
pred_smote_train_cls1_logistic = pred_smote_train_logistic[pred_smote_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_class0_logistic = accuracy_score(pred_smote_train_cls0_logistic['Class'],pred_smote_train_cls0_logistic['predicted'])
train_precision_smote_class0_logistic = precision_score(pred_smote_train_cls0_logistic['Class'],pred_smote_train_cls0_logistic['predicted'])
train_recall_smote_class0_logistic = recall_score(pred_smote_train_cls0_logistic['Class'],pred_smote_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_class1_logistic = accuracy_score(pred_smote_train_cls1_logistic['Class'],pred_smote_train_cls1_logistic['predicted'])
train_precision_smote_class1_logistic = precision_score(pred_smote_train_cls1_logistic['Class'],pred_smote_train_cls1_logistic['predicted'])
train_recall_smote_class1_logistic = recall_score(pred_smote_train_cls1_logistic['Class'],pred_smote_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_smote_logistic = Logistic_Regression_smote.predict(X_test_smote)
test_accuracy1_smote_logistic = accuracy_score(y_test_smote,test_pred_smote_logistic)
test_precision1_smote_logistic = precision_score(y_test_smote,test_pred_smote_logistic)
test_recall1_smote_logistic = recall_score(y_test_smote,test_pred_smote_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_logistic = confusion_matrix(y_test_smote,test_pred_smote_logistic)

cm_display_smote_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_smote_logistic.plot()
plt.title("Confusion Matrix - SMOTE Sampling -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_smote,X_test_smote,y_test_smote)

"""Class wise Accuracy"""

pred_smote_test_logistic = pd.DataFrame(y_test_smote)
pred_smote_test_logistic['predicted'] = test_pred_smote_logistic

pred_smote_test_logistic

pred_smote_test_cls0_logistic = pred_smote_test_logistic[pred_smote_test_logistic['Class'] == 0]
pred_smote_test_cls1_logistic = pred_smote_test_logistic[pred_smote_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_logistic = accuracy_score(pred_smote_test_cls0_logistic['Class'],pred_smote_test_cls0_logistic['predicted'])
test_precision_class0_smote_logistic = precision_score(pred_smote_test_cls0_logistic['Class'],pred_smote_test_cls0_logistic['predicted'])
test_recall_class0_smote_logistic = recall_score(pred_smote_test_cls0_logistic['Class'],pred_smote_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_logistic = accuracy_score(pred_smote_test_cls1_logistic['Class'],pred_smote_test_cls1_logistic['predicted'])
test_precision_class1_smote_logistic = precision_score(pred_smote_test_cls1_logistic['Class'],pred_smote_test_cls1_logistic['predicted'])
test_recall_class1_smote_logistic = recall_score(pred_smote_test_cls1_logistic['Class'],pred_smote_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_logistic*100,2)," %")

"""#### Random Forest Classifier"""

Random_Forest_smote = RandomForestClassifier()

"""Training Dataset"""

Random_Forest_smote.fit(X_train_smote_resampled,y_train_smote_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_RF = Random_Forest_smote.predict(X_train_smote_resampled)
train_accuracy_smote_RF = accuracy_score(y_train_smote_resampled,train_pred_smote_RF)
train_precision_smote_RF = precision_score(y_train_smote_resampled,train_pred_smote_RF)
train_recall_smote_RF = recall_score(y_train_smote_resampled,train_pred_smote_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_smote_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_RF*100,2)," %")

"""Classwise Accuracy"""

pred_smote_train_RF = pd.DataFrame(y_train_smote_resampled)
pred_smote_train_RF['predicted'] = train_pred_smote_RF
pred_smote_train_RF

pred_smote_train_cls0_RF = pred_smote_train_RF[pred_smote_train_RF['Class'] == 0]
pred_smote_train_cls1_RF = pred_smote_train_RF[pred_smote_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_class0_RF = accuracy_score(pred_smote_train_cls0_RF['Class'],pred_smote_train_cls0_RF['predicted'])
train_precision_smote_class0_RF = precision_score(pred_smote_train_cls0_RF['Class'],pred_smote_train_cls0_RF['predicted'])
train_recall_smote_class0_RF = recall_score(pred_smote_train_cls0_RF['Class'],pred_smote_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_class1_RF = accuracy_score(pred_smote_train_cls1_RF['Class'],pred_smote_train_cls1_RF['predicted'])
train_precision_smote_class1_RF = precision_score(pred_smote_train_cls1_RF['Class'],pred_smote_train_cls1_RF['predicted'])
train_recall_smote_class1_RF = recall_score(pred_smote_train_cls1_RF['Class'],pred_smote_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_smote_RF = Random_Forest_smote.predict(X_test_smote)
test_accuracy1_smote_RF = accuracy_score(y_test_smote,test_pred_smote_RF)
test_precision1_smote_RF = precision_score(y_test_smote,test_pred_smote_RF)
test_recall1_smote_RF = recall_score(y_test_smote,test_pred_smote_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_RF = confusion_matrix(y_test_smote,test_pred_smote_RF)

cm_display_smote_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_RF, display_labels = ['Normal', 'Fraud'])

cm_display_smote_RF.plot()
plt.title("Confusion Matrix - SMOTE Sampling -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_RF = RocCurveDisplay.from_estimator(Random_Forest_smote,X_test_smote,y_test_smote)

"""Class wise Accuracy"""

pred_smote_test_RF = pd.DataFrame(y_test_smote)
pred_smote_test_RF['predicted'] = test_pred_smote_RF

pred_smote_test_RF

pred_smote_test_cls0_RF = pred_smote_test_RF[pred_smote_test_RF['Class'] == 0]
pred_smote_test_cls1_RF = pred_smote_test_RF[pred_smote_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_RF = accuracy_score(pred_smote_test_cls0_RF['Class'],pred_smote_test_cls0_RF['predicted'])
test_precision_class0_smote_RF = precision_score(pred_smote_test_cls0_RF['Class'],pred_smote_test_cls0_RF['predicted'])
test_recall_class0_smote_RF = recall_score(pred_smote_test_cls0_RF['Class'],pred_smote_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_RF = accuracy_score(pred_smote_test_cls1_RF['Class'],pred_smote_test_cls1_RF['predicted'])
test_precision_class1_smote_RF = precision_score(pred_smote_test_cls1_RF['Class'],pred_smote_test_cls1_RF['predicted'])
test_recall_class1_smote_RF = recall_score(pred_smote_test_cls1_RF['Class'],pred_smote_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_RF*100,2)," %")

"""#### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

xgb_smote = xgb.XGBClassifier(objective="binary:logistic")

"""Training Dataset"""

xgb_smote.fit(X_train_smote_resampled,y_train_smote_resampled)

"""##### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_xgb = xgb_smote.predict(X_train_smote_resampled)
train_accuracy_smote_xgb = accuracy_score(y_train_smote_resampled,train_pred_smote_xgb)
train_precision_smote_xgb = precision_score(y_train_smote_resampled,train_pred_smote_xgb)
train_recall_smote_xgb = recall_score(y_train_smote_resampled,train_pred_smote_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_smote_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_smote_train_xgb = pd.DataFrame(y_train_smote_resampled)
pred_smote_train_xgb['predicted'] = train_pred_smote_xgb
pred_smote_train_xgb

pred_smote_train_cls0_xgb = pred_smote_train_xgb[pred_smote_train_xgb['Class'] == 0]
pred_smote_train_cls1_xgb = pred_smote_train_xgb[pred_smote_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_class0_xgb = accuracy_score(pred_smote_train_cls0_xgb['Class'],pred_smote_train_cls0_xgb['predicted'])
train_precision_smote_class0_xgb = precision_score(pred_smote_train_cls0_xgb['Class'],pred_smote_train_cls0_xgb['predicted'])
train_recall_smote_class0_xgb = recall_score(pred_smote_train_cls0_xgb['Class'],pred_smote_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_class1_xgb = accuracy_score(pred_smote_train_cls1_xgb['Class'],pred_smote_train_cls1_xgb['predicted'])
train_precision_smote_class1_xgb = precision_score(pred_smote_train_cls1_xgb['Class'],pred_smote_train_cls1_xgb['predicted'])
train_recall_smote_class1_xgb = recall_score(pred_smote_train_cls1_xgb['Class'],pred_smote_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_smote_xgb = xgb_smote.predict(X_test_smote)
test_accuracy1_smote_xgb = accuracy_score(y_test_smote,test_pred_smote_xgb)
test_precision1_smote_xgb = precision_score(y_test_smote,test_pred_smote_xgb)
test_recall1_smote_xgb = recall_score(y_test_smote,test_pred_smote_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_xgb = confusion_matrix(y_test_smote,test_pred_smote_xgb)

cm_display_smote_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_smote_xgb.plot()
plt.title("Confusion Matrix - SMOTE Sampling -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_xgb = RocCurveDisplay.from_estimator(xgb_smote,X_test_smote,y_test_smote)

"""Class wise Accuracy"""

pred_smote_test_xgb = pd.DataFrame(y_test_smote)
pred_smote_test_xgb['predicted'] = test_pred_smote_xgb

pred_smote_test_xgb

pred_smote_test_cls0_xgb = pred_smote_test_xgb[pred_smote_test_xgb['Class'] == 0]
pred_smote_test_cls1_xgb = pred_smote_test_xgb[pred_smote_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_xgb = accuracy_score(pred_smote_test_cls0_xgb['Class'],pred_smote_test_cls0_xgb['predicted'])
test_precision_class0_smote_xgb = precision_score(pred_smote_test_cls0_xgb['Class'],pred_smote_test_cls0_xgb['predicted'])
test_recall_class0_smote_xgb = recall_score(pred_smote_test_cls0_xgb['Class'],pred_smote_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_xgb = accuracy_score(pred_smote_test_cls1_xgb['Class'],pred_smote_test_cls1_xgb['predicted'])
test_precision_class1_smote_xgb = precision_score(pred_smote_test_cls1_xgb['Class'],pred_smote_test_cls1_xgb['predicted'])
test_recall_class1_smote_xgb = recall_score(pred_smote_test_cls1_xgb['Class'],pred_smote_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_xgb*100,2)," %")

"""#### Support Vector Machine Classifier




"""

svc_smote = SVC()

"""Training Dataset"""

svc_smote.fit(X_train_smote_resampled,y_train_smote_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_svc = svc_smote.predict(X_train_smote_resampled)
train_accuracy_smote_svc = accuracy_score(y_train_smote_resampled,train_pred_smote_svc)
train_precision_smote_svc = precision_score(y_train_smote_resampled,train_pred_smote_svc)
train_recall_smote_svc = recall_score(y_train_smote_resampled,train_pred_smote_svc)

print("Accuracy on Training Data is: ",round(train_accuracy_smote_svc*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_svc*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_svc*100,2)," %")

"""Classwise Accuracy"""

pred_smote_train_svc = pd.DataFrame(y_train_smote_resampled)
pred_smote_train_svc['predicted'] = train_pred_smote_svc
pred_smote_train_svc

pred_smote_train_cls0_svc = pred_smote_train_svc[pred_smote_train_svc['Class'] == 0]
pred_smote_train_cls1_svc = pred_smote_train_svc[pred_smote_train_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_class0_svc = accuracy_score(pred_smote_train_cls0_svc['Class'],pred_smote_train_cls0_svc['predicted'])
train_precision_smote_class0_svc = precision_score(pred_smote_train_cls0_svc['Class'],pred_smote_train_cls0_svc['predicted'])
train_recall_smote_class0_svc = recall_score(pred_smote_train_cls0_svc['Class'],pred_smote_train_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_class0_svc*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_class0_svc*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_class0_svc*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_class1_svc = accuracy_score(pred_smote_train_cls1_svc['Class'],pred_smote_train_cls1_svc['predicted'])
train_precision_smote_class1_svc = precision_score(pred_smote_train_cls1_svc['Class'],pred_smote_train_cls1_svc['predicted'])
train_recall_smote_class1_svc = recall_score(pred_smote_train_cls1_svc['Class'],pred_smote_train_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_class1_svc*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_class1_svc*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_class1_svc*100,2)," %")

"""On Testing Data"""

test_pred_smote_svc = svc_smote.predict(X_test_smote)
test_accuracy1_smote_svc = accuracy_score(y_test_smote,test_pred_smote_svc)
test_precision1_smote_svc = precision_score(y_test_smote,test_pred_smote_svc)
test_recall1_smote_svc = recall_score(y_test_smote,test_pred_smote_svc)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_svc*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_svc*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_svc*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_svc = confusion_matrix(y_test_smote,test_pred_smote_svc)

cm_display_smote_svc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_svc, display_labels = ['Normal', 'Fraud'])

cm_display_smote_svc.plot()
plt.title("Confusion Matrix - SMOTE Sampling -svc- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_svc = RocCurveDisplay.from_estimator(svc_smote,X_test_smote,y_test_smote)

"""Class wise Accuracy"""

pred_smote_test_svc = pd.DataFrame(y_test_smote)
pred_smote_test_svc['predicted'] = test_pred_smote_svc

pred_smote_test_svc

pred_smote_test_cls0_svc = pred_smote_test_svc[pred_smote_test_svc['Class'] == 0]
pred_smote_test_cls1_svc = pred_smote_test_svc[pred_smote_test_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_svc = accuracy_score(pred_smote_test_cls0_svc['Class'],pred_smote_test_cls0_svc['predicted'])
test_precision_class0_smote_svc = precision_score(pred_smote_test_cls0_svc['Class'],pred_smote_test_cls0_svc['predicted'])
test_recall_class0_smote_svc = recall_score(pred_smote_test_cls0_svc['Class'],pred_smote_test_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_svc*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_svc*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_svc*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_svc = accuracy_score(pred_smote_test_cls1_svc['Class'],pred_smote_test_cls1_svc['predicted'])
test_precision_class1_smote_svc = precision_score(pred_smote_test_cls1_svc['Class'],pred_smote_test_cls1_svc['predicted'])
test_recall_class1_smote_svc = recall_score(pred_smote_test_cls1_svc['Class'],pred_smote_test_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_svc*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_svc*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_svc*100,2)," %")

"""### Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Graph"""

Acc_smote_train_cls0 = [train_accuracy_smote_class0_logistic,train_accuracy_smote_class0_RF,train_accuracy_smote_class0_xgb,train_accuracy_smote_class0_svc]
Acc_smote_test_cls0 = [test_accuracy_class0_smote_logistic,test_accuracy_class0_smote_RF,test_accuracy_class0_smote_xgb,test_accuracy_class0_smote_svc]
Acc_smote_train_cls1 = [train_accuracy_smote_class1_logistic,train_accuracy_smote_class1_RF,train_accuracy_smote_class1_xgb,train_accuracy_smote_class1_svc]
Acc_smote_test_cls1 = [test_accuracy_class1_smote_logistic,test_accuracy_class1_smote_RF,test_accuracy_class1_smote_xgb,test_accuracy_class1_smote_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_smote_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_smote_train_cls0)

plt.plot(Model,Acc_smote_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_smote_test_cls0)

plt.plot(Model,Acc_smote_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_smote_train_cls1)

plt.plot(Model,Acc_smote_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_smote_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - SMOTE")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_smote_train_cls0 = [train_precision_smote_class0_logistic,train_precision_smote_class0_RF,train_precision_smote_class0_xgb,train_precision_smote_class0_svc]
Pre_smote_test_cls0 = [test_precision_class0_smote_logistic,test_precision_class0_smote_RF,test_precision_class0_smote_xgb,test_precision_class0_smote_svc]
Pre_smote_train_cls1 = [train_precision_smote_class1_logistic,train_precision_smote_class1_RF,train_precision_smote_class1_xgb,train_precision_smote_class1_svc]
Pre_smote_test_cls1 = [test_precision_class1_smote_logistic,test_precision_class1_smote_RF,test_precision_class1_smote_xgb,test_precision_class1_smote_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_smote_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_smote_train_cls0)

plt.plot(Model,Pre_smote_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_smote_test_cls0)

plt.plot(Model,Pre_smote_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_smote_train_cls1)

plt.plot(Model,Pre_smote_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_smote_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - SMOTE")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_smote_train_cls0 = [train_recall_smote_class0_logistic,train_recall_smote_class0_RF,train_recall_smote_class0_xgb,train_recall_smote_class0_svc]
Recall_smote_test_cls0 = [test_recall_class0_smote_logistic,test_recall_class0_smote_RF,test_recall_class0_smote_xgb,test_recall_class0_smote_svc]
Recall_smote_train_cls1 = [train_recall_smote_class1_logistic,train_recall_smote_class1_RF,train_recall_smote_class1_xgb,train_recall_smote_class1_svc]
Recall_smote_test_cls1 = [test_recall_class1_smote_logistic,test_recall_class1_smote_RF,test_recall_class1_smote_xgb,test_recall_class1_smote_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_smote_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_smote_train_cls0)

plt.plot(Model,Recall_smote_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_smote_test_cls0)

plt.plot(Model,Recall_smote_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_smote_train_cls1)

plt.plot(Model,Recall_smote_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_smote_test_cls1)

plt.ylabel("Recall")
plt.xlabel("Model")
plt.title("Comparision of Model Recall - SMOTE")
plt.legend()
plt.show()

"""# Combining Under-Sampling And Over-Sampling

## SMOTEENN technique

---

SMOTE + ENN

---

SMOTE (Synthetic Minority Over-sampling Technique) and Edited Nearest Neighbors (ENN)
"""

X_smote_enn = credit_df.drop("Class", axis="columns")
y_smote_enn = credit_df["Class"]

"""###Spliting into Train and Test Data"""

X_train_smote_enn,X_test_smote_enn,y_train_smote_enn,y_test_smote_enn = train_test_split(X_smote_enn, y_smote_enn , test_size = 0.25,random_state = 42)

from imblearn.combine import SMOTEENN

smote_enn = SMOTEENN(random_state = 42 )
X_train_smote_enn_resampled, y_train_smote_enn_resampled = smote_enn.fit_resample(X_train_smote_enn, y_train_smote_enn)

X_train_smote_resampled

y_train_smote_enn.value_counts()

"""###Model Training

####Logistic Regression Model
"""

Logistic_Regression_smote_enn = LogisticRegression()

"""Training Dataset"""

Logistic_Regression_smote_enn.fit(X_train_smote_enn_resampled,y_train_smote_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_enn_logistic = Logistic_Regression_smote_enn.predict(X_train_smote_enn_resampled)
train_accuracy_smote_enn_logistic = accuracy_score(y_train_smote_enn_resampled,train_pred_smote_enn_logistic)
train_precision_smote_enn_logistic = precision_score(y_train_smote_enn_resampled,train_pred_smote_enn_logistic)
train_recall_smote_enn_logistic = recall_score(y_train_smote_enn_resampled,train_pred_smote_enn_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_smote_enn_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_enn_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_enn_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_smote_enn_train_logistic = pd.DataFrame(y_train_smote_enn_resampled)
pred_smote_enn_train_logistic['predicted'] = train_pred_smote_enn_logistic
pred_smote_enn_train_logistic

pred_smote_enn_train_cls0_logistic = pred_smote_enn_train_logistic[pred_smote_enn_train_logistic['Class'] == 0]
pred_smote_enn_train_cls1_logistic = pred_smote_enn_train_logistic[pred_smote_enn_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_enn_class0_logistic = accuracy_score(pred_smote_enn_train_cls0_logistic['Class'],pred_smote_enn_train_cls0_logistic['predicted'])
train_precision_smote_enn_class0_logistic = precision_score(pred_smote_enn_train_cls0_logistic['Class'],pred_smote_enn_train_cls0_logistic['predicted'])
train_recall_smote_enn_class0_logistic = recall_score(pred_smote_enn_train_cls0_logistic['Class'],pred_smote_enn_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_enn_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_enn_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_enn_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_enn_class1_logistic = accuracy_score(pred_smote_enn_train_cls1_logistic['Class'],pred_smote_enn_train_cls1_logistic['predicted'])
train_precision_smote_enn_class1_logistic = precision_score(pred_smote_enn_train_cls1_logistic['Class'],pred_smote_enn_train_cls1_logistic['predicted'])
train_recall_smote_enn_class1_logistic = recall_score(pred_smote_enn_train_cls1_logistic['Class'],pred_smote_enn_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_enn_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_enn_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_enn_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_smote_enn_logistic = Logistic_Regression_smote_enn.predict(X_test_smote_enn)
test_accuracy1_smote_enn_logistic = accuracy_score(y_test_smote_enn,test_pred_smote_enn_logistic)
test_precision1_smote_enn_logistic = precision_score(y_test_smote_enn,test_pred_smote_enn_logistic)
test_recall1_smote_enn_logistic = recall_score(y_test_smote_enn,test_pred_smote_enn_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_enn_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_enn_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_enn_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_enn_logistic = confusion_matrix(y_test_smote_enn,test_pred_smote_enn_logistic)

cm_display_smote_enn_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_enn_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_smote_enn_logistic.plot()
plt.title("Confusion Matrix - SMOTEENN Sampling -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_enn_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_smote_enn,X_test_smote_enn,y_test_smote_enn)

"""Class wise Accuracy"""

pred_smote_enn_test_logistic = pd.DataFrame(y_test_smote_enn)
pred_smote_enn_test_logistic['predicted'] = test_pred_smote_enn_logistic

pred_smote_enn_test_logistic

pred_smote_enn_test_cls0_logistic = pred_smote_enn_test_logistic[pred_smote_enn_test_logistic['Class'] == 0]
pred_smote_enn_test_cls1_logistic = pred_smote_enn_test_logistic[pred_smote_enn_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_enn_logistic = accuracy_score(pred_smote_enn_test_cls0_logistic['Class'],pred_smote_enn_test_cls0_logistic['predicted'])
test_precision_class0_smote_enn_logistic = precision_score(pred_smote_enn_test_cls0_logistic['Class'],pred_smote_enn_test_cls0_logistic['predicted'])
test_recall_class0_smote_enn_logistic = recall_score(pred_smote_enn_test_cls0_logistic['Class'],pred_smote_enn_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_enn_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_enn_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_enn_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_enn_logistic = accuracy_score(pred_smote_enn_test_cls1_logistic['Class'],pred_smote_enn_test_cls1_logistic['predicted'])
test_precision_class1_smote_enn_logistic = precision_score(pred_smote_enn_test_cls1_logistic['Class'],pred_smote_enn_test_cls1_logistic['predicted'])
test_recall_class1_smote_enn_logistic = recall_score(pred_smote_enn_test_cls1_logistic['Class'],pred_smote_enn_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_enn_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_enn_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_enn_logistic*100,2)," %")

"""#### Random Forest Classifier"""

Random_Forest_smote_enn = RandomForestClassifier()

"""Training Dataset"""

Random_Forest_smote_enn.fit(X_train_smote_enn_resampled,y_train_smote_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_enn_RF = Random_Forest_smote_enn.predict(X_train_smote_enn_resampled)
train_accuracy_smote_enn_RF = accuracy_score(y_train_smote_enn_resampled,train_pred_smote_enn_RF)
train_precision_smote_enn_RF = precision_score(y_train_smote_enn_resampled,train_pred_smote_enn_RF)
train_recall_smote_enn_RF = recall_score(y_train_smote_enn_resampled,train_pred_smote_enn_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_smote_enn_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_enn_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_enn_RF*100,2)," %")

"""Classwise Accuracy"""

pred_smote_enn_train_RF = pd.DataFrame(y_train_smote_enn_resampled)
pred_smote_enn_train_RF['predicted'] = train_pred_smote_enn_RF
pred_smote_enn_train_RF

pred_smote_enn_train_cls0_RF = pred_smote_enn_train_RF[pred_smote_enn_train_RF['Class'] == 0]
pred_smote_enn_train_cls1_RF = pred_smote_enn_train_RF[pred_smote_enn_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_enn_class0_RF = accuracy_score(pred_smote_enn_train_cls0_RF['Class'],pred_smote_enn_train_cls0_RF['predicted'])
train_precision_smote_enn_class0_RF = precision_score(pred_smote_enn_train_cls0_RF['Class'],pred_smote_enn_train_cls0_RF['predicted'])
train_recall_smote_enn_class0_RF = recall_score(pred_smote_enn_train_cls0_RF['Class'],pred_smote_enn_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_enn_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_enn_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_enn_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_enn_class1_RF = accuracy_score(pred_smote_enn_train_cls1_RF['Class'],pred_smote_enn_train_cls1_RF['predicted'])
train_precision_smote_enn_class1_RF = precision_score(pred_smote_enn_train_cls1_RF['Class'],pred_smote_enn_train_cls1_RF['predicted'])
train_recall_smote_enn_class1_RF = recall_score(pred_smote_enn_train_cls1_RF['Class'],pred_smote_enn_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_enn_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_enn_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_enn_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_smote_enn_RF = Random_Forest_smote_enn.predict(X_test_smote_enn)
test_accuracy1_smote_enn_RF = accuracy_score(y_test_smote_enn,test_pred_smote_enn_RF)
test_precision1_smote_enn_RF = precision_score(y_test_smote_enn,test_pred_smote_enn_RF)
test_recall1_smote_enn_RF = recall_score(y_test_smote_enn,test_pred_smote_enn_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_enn_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_enn_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_enn_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_enn_RF = confusion_matrix(y_test_smote_enn,test_pred_smote_enn_RF)

cm_display_smote_enn_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_enn_RF, display_labels = ['Normal', 'Fraud'])

cm_display_smote_enn_RF.plot()
plt.title("Confusion Matrix - SMOTEENN Sampling -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_enn_RF = RocCurveDisplay.from_estimator(Random_Forest_smote_enn,X_test_smote_enn,y_test_smote_enn)

"""Class wise Accuracy"""

pred_smote_enn_test_RF = pd.DataFrame(y_test_smote_enn)
pred_smote_enn_test_RF['predicted'] = test_pred_smote_enn_RF

pred_smote_enn_test_RF

pred_smote_enn_test_cls0_RF = pred_smote_enn_test_RF[pred_smote_enn_test_RF['Class'] == 0]
pred_smote_enn_test_cls1_RF = pred_smote_enn_test_RF[pred_smote_enn_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_enn_RF = accuracy_score(pred_smote_enn_test_cls0_RF['Class'],pred_smote_enn_test_cls0_RF['predicted'])
test_precision_class0_smote_enn_RF = precision_score(pred_smote_enn_test_cls0_RF['Class'],pred_smote_enn_test_cls0_RF['predicted'])
test_recall_class0_smote_enn_RF = recall_score(pred_smote_enn_test_cls0_RF['Class'],pred_smote_enn_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_enn_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_enn_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_enn_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_enn_RF = accuracy_score(pred_smote_enn_test_cls1_RF['Class'],pred_smote_enn_test_cls1_RF['predicted'])
test_precision_class1_smote_enn_RF = precision_score(pred_smote_enn_test_cls1_RF['Class'],pred_smote_enn_test_cls1_RF['predicted'])
test_recall_class1_smote_enn_RF = recall_score(pred_smote_enn_test_cls1_RF['Class'],pred_smote_enn_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_enn_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_enn_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_enn_RF*100,2)," %")

"""#### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

xgb_smote_enn = xgb.XGBClassifier(objective="binary:logistic")

"""Training Dataset"""

xgb_smote_enn.fit(X_train_smote_enn_resampled,y_train_smote_enn_resampled)

"""##### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_enn_xgb = xgb_smote_enn.predict(X_train_smote_enn_resampled)
train_accuracy_smote_enn_xgb = accuracy_score(y_train_smote_enn_resampled,train_pred_smote_enn_xgb)
train_precision_smote_enn_xgb = precision_score(y_train_smote_enn_resampled,train_pred_smote_enn_xgb)
train_recall_smote_enn_xgb = recall_score(y_train_smote_enn_resampled,train_pred_smote_enn_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_smote_enn_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_enn_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_enn_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_smote_enn_train_xgb = pd.DataFrame(y_train_smote_enn_resampled)
pred_smote_enn_train_xgb['predicted'] = train_pred_smote_enn_xgb
pred_smote_enn_train_xgb

pred_smote_enn_train_cls0_xgb = pred_smote_enn_train_xgb[pred_smote_enn_train_xgb['Class'] == 0]
pred_smote_enn_train_cls1_xgb = pred_smote_enn_train_xgb[pred_smote_enn_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_enn_class0_xgb = accuracy_score(pred_smote_enn_train_cls0_xgb['Class'],pred_smote_enn_train_cls0_xgb['predicted'])
train_precision_smote_enn_class0_xgb = precision_score(pred_smote_enn_train_cls0_xgb['Class'],pred_smote_enn_train_cls0_xgb['predicted'])
train_recall_smote_enn_class0_xgb = recall_score(pred_smote_enn_train_cls0_xgb['Class'],pred_smote_enn_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_enn_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_enn_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_enn_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_enn_class1_xgb = accuracy_score(pred_smote_enn_train_cls1_xgb['Class'],pred_smote_enn_train_cls1_xgb['predicted'])
train_precision_smote_enn_class1_xgb = precision_score(pred_smote_enn_train_cls1_xgb['Class'],pred_smote_enn_train_cls1_xgb['predicted'])
train_recall_smote_enn_class1_xgb = recall_score(pred_smote_enn_train_cls1_xgb['Class'],pred_smote_enn_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_enn_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_enn_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_enn_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_smote_enn_xgb = xgb_smote_enn.predict(X_test_smote_enn)
test_accuracy1_smote_enn_xgb = accuracy_score(y_test_smote_enn,test_pred_smote_enn_xgb)
test_precision1_smote_enn_xgb = precision_score(y_test_smote_enn,test_pred_smote_enn_xgb)
test_recall1_smote_enn_xgb = recall_score(y_test_smote_enn,test_pred_smote_enn_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_enn_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_enn_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_enn_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_enn_xgb = confusion_matrix(y_test_smote_enn,test_pred_smote_enn_xgb)

cm_display_smote_enn_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_enn_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_smote_enn_xgb.plot()
plt.title("Confusion Matrix - SMOTEENN Sampling -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_enn_xgb = RocCurveDisplay.from_estimator(xgb_smote_enn,X_test_smote_enn,y_test_smote_enn)

"""Class wise Accuracy"""

pred_smote_enn_test_xgb = pd.DataFrame(y_test_smote_enn)
pred_smote_enn_test_xgb['predicted'] = test_pred_smote_enn_xgb

pred_smote_enn_test_xgb

pred_smote_enn_test_cls0_xgb = pred_smote_enn_test_xgb[pred_smote_enn_test_xgb['Class'] == 0]
pred_smote_enn_test_cls1_xgb = pred_smote_enn_test_xgb[pred_smote_enn_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_enn_xgb = accuracy_score(pred_smote_enn_test_cls0_xgb['Class'],pred_smote_enn_test_cls0_xgb['predicted'])
test_precision_class0_smote_enn_xgb = precision_score(pred_smote_enn_test_cls0_xgb['Class'],pred_smote_enn_test_cls0_xgb['predicted'])
test_recall_class0_smote_enn_xgb = recall_score(pred_smote_enn_test_cls0_xgb['Class'],pred_smote_enn_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_enn_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_enn_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_enn_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_enn_xgb = accuracy_score(pred_smote_enn_test_cls1_xgb['Class'],pred_smote_enn_test_cls1_xgb['predicted'])
test_precision_class1_smote_enn_xgb = precision_score(pred_smote_enn_test_cls1_xgb['Class'],pred_smote_enn_test_cls1_xgb['predicted'])
test_recall_class1_smote_enn_xgb = recall_score(pred_smote_enn_test_cls1_xgb['Class'],pred_smote_enn_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_enn_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_enn_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_enn_xgb*100,2)," %")

"""#### Support Vector Machine Classifier




"""

svc_smote_enn = SVC()

"""Training Dataset"""

svc_smote_enn.fit(X_train_smote_enn_resampled,y_train_smote_enn_resampled)

"""#####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_smote_enn_svc = svc_smote_enn.predict(X_train_smote_enn_resampled)
train_accuracy_smote_enn_svc = accuracy_score(y_train_smote_enn_resampled,train_pred_smote_enn_svc)
train_precision_smote_enn_svc = precision_score(y_train_smote_enn_resampled,train_pred_smote_enn_svc)
train_recall_smote_enn_svc = recall_score(y_train_smote_enn_resampled,train_pred_smote_enn_svc)

print("Accuracy on Training Data is: ",round(train_accuracy_smote_enn_svc*100,2)," %")
print("precision on Training Data is: ",round(train_precision_smote_enn_svc*100,2)," %")
print("recall on Training Data is: ",round(train_recall_smote_enn_svc*100,2)," %")

"""Classwise Accuracy"""

pred_smote_enn_train_svc = pd.DataFrame(y_train_smote_enn_resampled)
pred_smote_enn_train_svc['predicted'] = train_pred_smote_enn_svc
pred_smote_enn_train_svc

pred_smote_enn_train_cls0_svc = pred_smote_enn_train_svc[pred_smote_enn_train_svc['Class'] == 0]
pred_smote_enn_train_cls1_svc = pred_smote_enn_train_svc[pred_smote_enn_train_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_smote_enn_class0_svc = accuracy_score(pred_smote_enn_train_cls0_svc['Class'],pred_smote_enn_train_cls0_svc['predicted'])
train_precision_smote_enn_class0_svc = precision_score(pred_smote_enn_train_cls0_svc['Class'],pred_smote_enn_train_cls0_svc['predicted'])
train_recall_smote_enn_class0_svc = recall_score(pred_smote_enn_train_cls0_svc['Class'],pred_smote_enn_train_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_smote_enn_class0_svc*100,2)," %")
print("precision of Class 0: ",round(train_precision_smote_enn_class0_svc*100,2)," %")
print("recall of Class 0: ",round(train_recall_smote_enn_class0_svc*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_smote_enn_class1_svc = accuracy_score(pred_smote_enn_train_cls1_svc['Class'],pred_smote_enn_train_cls1_svc['predicted'])
train_precision_smote_enn_class1_svc = precision_score(pred_smote_enn_train_cls1_svc['Class'],pred_smote_enn_train_cls1_svc['predicted'])
train_recall_smote_enn_class1_svc = recall_score(pred_smote_enn_train_cls1_svc['Class'],pred_smote_enn_train_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_smote_enn_class1_svc*100,2)," %")
print("precision of Class 1: ",round(train_precision_smote_enn_class1_svc*100,2)," %")
print("recall of Class 1: ",round(train_recall_smote_enn_class1_svc*100,2)," %")

"""On Testing Data"""

test_pred_smote_enn_svc = svc_smote_enn.predict(X_test_smote_enn)
test_accuracy1_smote_enn_svc = accuracy_score(y_test_smote_enn,test_pred_smote_enn_svc)
test_precision1_smote_enn_svc = precision_score(y_test_smote_enn,test_pred_smote_enn_svc)
test_recall1_smote_enn_svc = recall_score(y_test_smote_enn,test_pred_smote_enn_svc)


print("Accuracy on Testing Data is: ",round(test_accuracy1_smote_enn_svc*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_smote_enn_svc*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_smote_enn_svc*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_smote_enn_svc = confusion_matrix(y_test_smote_enn,test_pred_smote_enn_svc)

cm_display_smote_enn_svc = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_smote_enn_svc, display_labels = ['Normal', 'Fraud'])

cm_display_smote_enn_svc.plot()
plt.title("Confusion Matrix - SMOTEENN Sampling -svc- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_smote_enn_svc = RocCurveDisplay.from_estimator(svc_smote_enn,X_test_smote_enn,y_test_smote_enn)

"""Class wise Accuracy"""

pred_smote_enn_test_svc = pd.DataFrame(y_test_smote_enn)
pred_smote_enn_test_svc['predicted'] = test_pred_smote_enn_svc

pred_smote_enn_test_svc

pred_smote_enn_test_cls0_svc = pred_smote_enn_test_svc[pred_smote_enn_test_svc['Class'] == 0]
pred_smote_enn_test_cls1_svc = pred_smote_enn_test_svc[pred_smote_enn_test_svc['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_smote_enn_svc = accuracy_score(pred_smote_enn_test_cls0_svc['Class'],pred_smote_enn_test_cls0_svc['predicted'])
test_precision_class0_smote_enn_svc = precision_score(pred_smote_enn_test_cls0_svc['Class'],pred_smote_enn_test_cls0_svc['predicted'])
test_recall_class0_smote_enn_svc = recall_score(pred_smote_enn_test_cls0_svc['Class'],pred_smote_enn_test_cls0_svc['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_smote_enn_svc*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_smote_enn_svc*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_smote_enn_svc*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_smote_enn_svc = accuracy_score(pred_smote_enn_test_cls1_svc['Class'],pred_smote_enn_test_cls1_svc['predicted'])
test_precision_class1_smote_enn_svc = precision_score(pred_smote_enn_test_cls1_svc['Class'],pred_smote_enn_test_cls1_svc['predicted'])
test_recall_class1_smote_enn_svc = recall_score(pred_smote_enn_test_cls1_svc['Class'],pred_smote_enn_test_cls1_svc['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_smote_enn_svc*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_smote_enn_svc*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_smote_enn_svc*100,2)," %")

"""### Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Graph"""

Acc_smote_enn_train_cls0 = [train_accuracy_smote_enn_class0_logistic,train_accuracy_smote_enn_class0_RF,train_accuracy_smote_enn_class0_xgb,train_accuracy_smote_enn_class0_svc]
Acc_smote_enn_test_cls0 = [test_accuracy_class0_smote_enn_logistic,test_accuracy_class0_smote_enn_RF,test_accuracy_class0_smote_enn_xgb,test_accuracy_class0_smote_enn_svc]
Acc_smote_enn_train_cls1 = [train_accuracy_smote_enn_class1_logistic,train_accuracy_smote_enn_class1_RF,train_accuracy_smote_enn_class1_xgb,train_accuracy_smote_enn_class1_svc]
Acc_smote_enn_test_cls1 = [test_accuracy_class1_smote_enn_logistic,test_accuracy_class1_smote_enn_RF,test_accuracy_class1_smote_enn_xgb,test_accuracy_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_smote_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_smote_enn_train_cls0)

plt.plot(Model,Acc_smote_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_smote_enn_test_cls0)

plt.plot(Model,Acc_smote_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_smote_enn_train_cls1)

plt.plot(Model,Acc_smote_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_smote_enn_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - SMOTEENN")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_smote_enn_train_cls0 = [train_precision_smote_enn_class0_logistic,train_precision_smote_enn_class0_RF,train_precision_smote_enn_class0_xgb,train_precision_smote_enn_class0_svc]
Pre_smote_enn_test_cls0 = [test_precision_class0_smote_enn_logistic,test_precision_class0_smote_enn_RF,test_precision_class0_smote_enn_xgb,test_precision_class0_smote_enn_svc]
Pre_smote_enn_train_cls1 = [train_precision_smote_enn_class1_logistic,train_precision_smote_enn_class1_RF,train_precision_smote_enn_class1_xgb,train_precision_smote_enn_class1_svc]
Pre_smote_enn_test_cls1 = [test_precision_class1_smote_enn_logistic,test_precision_class1_smote_enn_RF,test_precision_class1_smote_enn_xgb,test_precision_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_smote_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_smote_enn_train_cls0)

plt.plot(Model,Pre_smote_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_smote_enn_test_cls0)

plt.plot(Model,Pre_smote_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_smote_enn_train_cls1)

plt.plot(Model,Pre_smote_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_smote_enn_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - SMOTEENN")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_smote_enn_train_cls0 = [train_recall_smote_enn_class0_logistic,train_recall_smote_enn_class0_RF,train_recall_smote_enn_class0_xgb,train_recall_smote_enn_class0_svc]
Recall_smote_enn_test_cls0 = [test_recall_class0_smote_enn_logistic,test_recall_class0_smote_enn_RF,test_recall_class0_smote_enn_xgb,test_recall_class0_smote_enn_svc]
Recall_smote_enn_train_cls1 = [train_recall_smote_enn_class1_logistic,train_recall_smote_enn_class1_RF,train_recall_smote_enn_class1_xgb,train_recall_smote_enn_class1_svc]
Recall_smote_enn_test_cls1 = [test_recall_class1_smote_enn_logistic,test_recall_class1_smote_enn_RF,test_recall_class1_smote_enn_xgb,test_recall_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_smote_enn_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_smote_enn_train_cls0)

plt.plot(Model,Recall_smote_enn_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_smote_enn_test_cls0)

plt.plot(Model,Recall_smote_enn_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_smote_enn_train_cls1)

plt.plot(Model,Recall_smote_enn_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_smote_enn_test_cls1)

plt.xlabel("Model")
plt.ylabel("Recall")
plt.title("Comparision of Model Recall - SMOTEENN")
plt.legend()
plt.show()

"""# Overall Comparision of Sampling Techniques"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","SVM Classifier"]

"""Accuracy Plots for Test Data Class 1"""

Acc_under_test_cls1 = [test_accuracy_class1_under_logistic,test_accuracy_class1_under_RF,test_accuracy_class1_under_xgb,test_accuracy_class1_under_svc]
Acc_enn_test_cls1 = [test_accuracy_class1_enn_logistic,test_accuracy_class1_enn_RF,test_accuracy_class1_enn_xgb,test_accuracy_class1_enn_svc]
Acc_over_test_cls1 = [test_accuracy_class1_over_logistic,test_accuracy_class1_over_RF,test_accuracy_class1_over_xgb,test_accuracy_class1_over_svc]
Acc_smote_test_cls1 = [test_accuracy_class1_smote_logistic,test_accuracy_class1_smote_RF,test_accuracy_class1_smote_xgb,test_accuracy_class1_smote_svc]
Acc_smote_enn_test_cls1 = [test_accuracy_class1_smote_enn_logistic,test_accuracy_class1_smote_enn_RF,test_accuracy_class1_smote_enn_xgb,test_accuracy_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_under_test_cls1,label = "Random Under Sampling: test class 1")
plt.scatter(Model,Acc_under_test_cls1)

plt.plot(Model,Acc_enn_test_cls1,label = "ENN Sampling: test class 1")
plt.scatter(Model,Acc_enn_test_cls1)

plt.plot(Model,Acc_over_test_cls1,label = "Random Over Sampling: test class 1")
plt.scatter(Model,Acc_over_test_cls1)

plt.plot(Model,Acc_smote_test_cls1,label = "SMOTE Sampling: test class 1")
plt.scatter(Model,Acc_smote_test_cls1)

plt.plot(Model,Acc_smote_enn_test_cls1,label = "SMOTEENN Sampling: test class 1")
plt.scatter(Model,Acc_smote_enn_test_cls1)

plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Comparision of Accuracy of Test Data Class 1")

plt.legend()
plt.show()

"""Precision Plots for Test Data Class 1"""

Pre_under_test_cls1 = [test_precision_class1_under_logistic,test_precision_class1_under_RF,test_precision_class1_under_xgb,test_precision_class1_under_svc]
Pre_enn_test_cls1 = [test_precision_class1_enn_logistic,test_precision_class1_enn_RF,test_precision_class1_enn_xgb,test_precision_class1_enn_svc]
Pre_over_test_cls1 = [test_precision_class1_over_logistic,test_precision_class1_over_RF,test_precision_class1_over_xgb,test_precision_class1_over_svc]
Pre_smote_test_cls1 = [test_precision_class1_smote_logistic,test_precision_class1_smote_RF,test_precision_class1_smote_xgb,test_precision_class1_smote_svc]
Pre_smote_enn_test_cls1 = [test_precision_class1_smote_enn_logistic,test_precision_class1_smote_enn_RF,test_precision_class1_smote_enn_xgb,test_precision_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_under_test_cls1,label = "Random Under Sampling: test class 1")
plt.scatter(Model,Pre_under_test_cls1)

plt.plot(Model,Pre_enn_test_cls1,label = "ENN Sampling: test class 1")
plt.scatter(Model,Pre_enn_test_cls1)

plt.plot(Model,Pre_over_test_cls1,label = "Random Over Sampling: test class 1")
plt.scatter(Model,Pre_over_test_cls1)

plt.plot(Model,Pre_smote_test_cls1,label = "SMOTE Sampling: test class 1")
plt.scatter(Model,Pre_smote_test_cls1)

plt.plot(Model,Pre_smote_enn_test_cls1,label = "SMOTEENN Sampling: test class 1")
plt.scatter(Model,Pre_smote_enn_test_cls1)

plt.xlabel("Model")
plt.ylabel("Precision")
plt.title("Comparision of Precision of Test Data Class 1")

plt.legend()
plt.show()

"""Recall Plots for Test Data Class 1"""

Recall_under_test_cls1 = [test_recall_class1_under_logistic,test_recall_class1_under_RF,test_recall_class1_under_xgb,test_recall_class1_under_svc]
Recall_enn_test_cls1 = [test_recall_class1_enn_logistic,test_recall_class1_enn_RF,test_recall_class1_enn_xgb,test_recall_class1_enn_svc]
Recall_over_test_cls1 = [test_recall_class1_over_logistic,test_recall_class1_over_RF,test_recall_class1_over_xgb,test_recall_class1_over_svc]
Recall_smote_test_cls1 = [test_recall_class1_smote_logistic,test_recall_class1_smote_RF,test_recall_class1_smote_xgb,test_recall_class1_smote_svc]
Recall_smote_enn_test_cls1 = [test_recall_class1_smote_enn_logistic,test_recall_class1_smote_enn_RF,test_recall_class1_smote_enn_xgb,test_recall_class1_smote_enn_svc]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_under_test_cls1,label = "Random Under Sampling: test class 1")
plt.scatter(Model,Recall_under_test_cls1)

plt.plot(Model,Recall_enn_test_cls1,label = "ENN Sampling: test class 1")
plt.scatter(Model,Recall_enn_test_cls1)

plt.plot(Model,Recall_over_test_cls1,label = "Random Over Sampling: test class 1")
plt.scatter(Model,Recall_over_test_cls1)

plt.plot(Model,Recall_smote_test_cls1,label = "SMOTE Sampling: test class 1")
plt.scatter(Model,Recall_smote_test_cls1)

plt.plot(Model,Recall_smote_enn_test_cls1,label = "SMOTEENN Sampling: test class 1")
plt.scatter(Model,Recall_smote_enn_test_cls1)

plt.xlabel("Model")
plt.ylabel("Recall")
plt.title("Comparision of Recall of Test Data Class 1")

plt.legend()
plt.show()

"""# Cost Sensitive Learning

---
using class_weights parameter to assign different weights to diffenet classes


"""

X_cost = credit_df.drop(columns=['Class'],axis = 1)
y_cost = credit_df['Class']

"""## Splitting into Train and Test Data"""

X_train_cost,X_test_cost,y_train_cost,y_test_cost = train_test_split(X_cost, y_cost , test_size = 0.25,random_state = 42)

"""## Model Training

### Logistic Regression Model
"""

Logistic_Regression_cost = LogisticRegression(class_weight = 'balanced')

"""Training Dataset"""

Logistic_Regression_cost.fit(X_train_cost,y_train_cost)

"""####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_cost_logistic = Logistic_Regression_cost.predict(X_train_cost)
train_accuracy_cost_logistic = accuracy_score(y_train_cost,train_pred_cost_logistic)
train_precision_cost_logistic = precision_score(y_train_cost,train_pred_cost_logistic)
train_recall_cost_logistic = recall_score(y_train_cost,train_pred_cost_logistic)

print("Accuracy on Training Data is: ",round(train_accuracy_cost_logistic*100,2)," %")
print("precision on Training Data is: ",round(train_precision_cost_logistic*100,2)," %")
print("recall on Training Data is: ",round(train_recall_cost_logistic*100,2)," %")

"""Classwise Accuracy"""

pred_cost_train_logistic = pd.DataFrame(y_train_cost)
pred_cost_train_logistic['predicted'] = train_pred_cost_logistic
pred_cost_train_logistic

pred_cost_train_cls0_logistic = pred_cost_train_logistic[pred_cost_train_logistic['Class'] == 0]
pred_cost_train_cls1_logistic = pred_cost_train_logistic[pred_cost_train_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_cost_class0_logistic = accuracy_score(pred_cost_train_cls0_logistic['Class'],pred_cost_train_cls0_logistic['predicted'])
train_precision_cost_class0_logistic = precision_score(pred_cost_train_cls0_logistic['Class'],pred_cost_train_cls0_logistic['predicted'])
train_recall_cost_class0_logistic = recall_score(pred_cost_train_cls0_logistic['Class'],pred_cost_train_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_cost_class0_logistic*100,2)," %")
print("precision of Class 0: ",round(train_precision_cost_class0_logistic*100,2)," %")
print("recall of Class 0: ",round(train_recall_cost_class0_logistic*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_cost_class1_logistic = accuracy_score(pred_cost_train_cls1_logistic['Class'],pred_cost_train_cls1_logistic['predicted'])
train_precision_cost_class1_logistic = precision_score(pred_cost_train_cls1_logistic['Class'],pred_cost_train_cls1_logistic['predicted'])
train_recall_cost_class1_logistic = recall_score(pred_cost_train_cls1_logistic['Class'],pred_cost_train_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_cost_class1_logistic*100,2)," %")
print("precision of Class 1: ",round(train_precision_cost_class1_logistic*100,2)," %")
print("recall of Class 1: ",round(train_recall_cost_class1_logistic*100,2)," %")

"""On Testing Data"""

test_pred_cost_logistic = Logistic_Regression_cost.predict(X_test_cost)
test_accuracy1_cost_logistic = accuracy_score(y_test_cost,test_pred_cost_logistic)
test_precision1_cost_logistic = precision_score(y_test_cost,test_pred_cost_logistic)
test_recall1_cost_logistic = recall_score(y_test_cost,test_pred_cost_logistic)


print("Accuracy on Testing Data is: ",round(test_accuracy1_cost_logistic*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_cost_logistic*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_cost_logistic*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_cost_logistic = confusion_matrix(y_test_cost,test_pred_cost_logistic)

cm_display_cost_logistic = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_cost_logistic, display_labels = ['Normal', 'Fraud'])

cm_display_cost_logistic.plot()
plt.title("Confusion Matrix - Cost Sensitive Learning -logistic- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_cost_logistic = RocCurveDisplay.from_estimator(Logistic_Regression_cost,X_test_cost,y_test_cost)

"""Class wise Accuracy"""

pred_cost_test_logistic = pd.DataFrame(y_test_cost)
pred_cost_test_logistic['predicted'] = test_pred_cost_logistic

pred_cost_test_logistic

pred_cost_test_cls0_logistic = pred_cost_test_logistic[pred_cost_test_logistic['Class'] == 0]
pred_cost_test_cls1_logistic = pred_cost_test_logistic[pred_cost_test_logistic['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_cost_logistic = accuracy_score(pred_cost_test_cls0_logistic['Class'],pred_cost_test_cls0_logistic['predicted'])
test_precision_class0_cost_logistic = precision_score(pred_cost_test_cls0_logistic['Class'],pred_cost_test_cls0_logistic['predicted'])
test_recall_class0_cost_logistic = recall_score(pred_cost_test_cls0_logistic['Class'],pred_cost_test_cls0_logistic['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_cost_logistic*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_cost_logistic*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_cost_logistic*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_cost_logistic = accuracy_score(pred_cost_test_cls1_logistic['Class'],pred_cost_test_cls1_logistic['predicted'])
test_precision_class1_cost_logistic = precision_score(pred_cost_test_cls1_logistic['Class'],pred_cost_test_cls1_logistic['predicted'])
test_recall_class1_cost_logistic = recall_score(pred_cost_test_cls1_logistic['Class'],pred_cost_test_cls1_logistic['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_cost_logistic*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_cost_logistic*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_cost_logistic*100,2)," %")

"""### Random Forest Classifier"""

Random_Forest_cost = RandomForestClassifier(class_weight = 'balanced')

"""Training Dataset"""

Random_Forest_cost.fit(X_train_cost,y_train_cost)

"""####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_cost_RF = Random_Forest_cost.predict(X_train_cost)
train_accuracy_cost_RF = accuracy_score(y_train_cost,train_pred_cost_RF)
train_precision_cost_RF = precision_score(y_train_cost,train_pred_cost_RF)
train_recall_cost_RF = recall_score(y_train_cost,train_pred_cost_RF)


print("Accuracy on Training Data is: ",round(train_accuracy_cost_RF*100,2)," %")
print("precision on Training Data is: ",round(train_precision_cost_RF*100,2)," %")
print("recall on Training Data is: ",round(train_recall_cost_RF*100,2)," %")

"""Classwise Accuracy"""

pred_cost_train_RF = pd.DataFrame(y_train_cost)
pred_cost_train_RF['predicted'] = train_pred_cost_RF
pred_cost_train_RF

pred_cost_train_cls0_RF = pred_cost_train_RF[pred_cost_train_RF['Class'] == 0]
pred_cost_train_cls1_RF = pred_cost_train_RF[pred_cost_train_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_cost_class0_RF = accuracy_score(pred_cost_train_cls0_RF['Class'],pred_cost_train_cls0_RF['predicted'])
train_precision_cost_class0_RF = precision_score(pred_cost_train_cls0_RF['Class'],pred_cost_train_cls0_RF['predicted'])
train_recall_cost_class0_RF = recall_score(pred_cost_train_cls0_RF['Class'],pred_cost_train_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_cost_class0_RF*100,2)," %")
print("precision of Class 0: ",round(train_precision_cost_class0_RF*100,2)," %")
print("recall of Class 0: ",round(train_recall_cost_class0_RF*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_cost_class1_RF = accuracy_score(pred_cost_train_cls1_RF['Class'],pred_cost_train_cls1_RF['predicted'])
train_precision_cost_class1_RF = precision_score(pred_cost_train_cls1_RF['Class'],pred_cost_train_cls1_RF['predicted'])
train_recall_cost_class1_RF = recall_score(pred_cost_train_cls1_RF['Class'],pred_cost_train_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_cost_class1_RF*100,2)," %")
print("precision of Class 1: ",round(train_precision_cost_class1_RF*100,2)," %")
print("recall of Class 1: ",round(train_recall_cost_class1_RF*100,2)," %")

"""On Testing Data"""

test_pred_cost_RF = Random_Forest_cost.predict(X_test_cost)
test_accuracy1_cost_RF = accuracy_score(y_test_cost,test_pred_cost_RF)
test_precision1_cost_RF = precision_score(y_test_cost,test_pred_cost_RF)
test_recall1_cost_RF = recall_score(y_test_cost,test_pred_cost_RF)


print("Accuracy on Testing Data is: ",round(test_accuracy1_cost_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_cost_RF*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_cost_RF*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_cost_RF = confusion_matrix(y_test_cost,test_pred_cost_RF)

cm_display_cost_RF = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_cost_RF, display_labels = ['Normal', 'Fraud'])

cm_display_cost_RF.plot()
plt.title("Confusion Matrix - Cost Sensitive Learning -RF- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_cost_RF = RocCurveDisplay.from_estimator(Random_Forest_cost,X_test_cost,y_test_cost)

"""Class wise Accuracy"""

pred_cost_test_RF = pd.DataFrame(y_test_cost)
pred_cost_test_RF['predicted'] = test_pred_cost_RF

pred_cost_test_RF

pred_cost_test_cls0_RF = pred_cost_test_RF[pred_cost_test_RF['Class'] == 0]
pred_cost_test_cls1_RF = pred_cost_test_RF[pred_cost_test_RF['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_cost_RF = accuracy_score(pred_cost_test_cls0_RF['Class'],pred_cost_test_cls0_RF['predicted'])
test_precision_class0_cost_RF = precision_score(pred_cost_test_cls0_RF['Class'],pred_cost_test_cls0_RF['predicted'])
test_recall_class0_cost_RF = recall_score(pred_cost_test_cls0_RF['Class'],pred_cost_test_cls0_RF['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_cost_RF*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_cost_RF*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_cost_RF*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_cost_RF = accuracy_score(pred_cost_test_cls1_RF['Class'],pred_cost_test_cls1_RF['predicted'])
test_precision_class1_cost_RF = precision_score(pred_cost_test_cls1_RF['Class'],pred_cost_test_cls1_RF['predicted'])
test_recall_class1_cost_RF = recall_score(pred_cost_test_cls1_RF['Class'],pred_cost_test_cls1_RF['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_cost_RF*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_cost_RF*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_cost_RF*100,2)," %")

"""### Xtreme Gradient Boosting Classifier (XGBClassifier) """

import xgboost as xgb

l0 = len(Normal_df)
l1 = len(Fraud_df)

xgb_cost = xgb.XGBClassifier(objective="binary:logistic",scale_pos_weight = l0/l1)

"""Training Dataset"""

xgb_cost.fit(X_train_cost,y_train_cost)

"""#### Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_cost_xgb = xgb_cost.predict(X_train_cost)
train_accuracy_cost_xgb = accuracy_score(y_train_cost,train_pred_cost_xgb)
train_precision_cost_xgb = precision_score(y_train_cost,train_pred_cost_xgb)
train_recall_cost_xgb = recall_score(y_train_cost,train_pred_cost_xgb)


print("Accuracy on Training Data is: ",round(train_accuracy_cost_xgb*100,2)," %")
print("precision on Training Data is: ",round(train_precision_cost_xgb*100,2)," %")
print("recall on Training Data is: ",round(train_recall_cost_xgb*100,2)," %")

"""Classwise Accuracy"""

pred_cost_train_xgb = pd.DataFrame(y_train_cost)
pred_cost_train_xgb['predicted'] = train_pred_cost_xgb
pred_cost_train_xgb

pred_cost_train_cls0_xgb = pred_cost_train_xgb[pred_cost_train_xgb['Class'] == 0]
pred_cost_train_cls1_xgb = pred_cost_train_xgb[pred_cost_train_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_cost_class0_xgb = accuracy_score(pred_cost_train_cls0_xgb['Class'],pred_cost_train_cls0_xgb['predicted'])
train_precision_cost_class0_xgb = precision_score(pred_cost_train_cls0_xgb['Class'],pred_cost_train_cls0_xgb['predicted'])
train_recall_cost_class0_xgb = recall_score(pred_cost_train_cls0_xgb['Class'],pred_cost_train_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_cost_class0_xgb*100,2)," %")
print("precision of Class 0: ",round(train_precision_cost_class0_xgb*100,2)," %")
print("recall of Class 0: ",round(train_recall_cost_class0_xgb*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_cost_class1_xgb = accuracy_score(pred_cost_train_cls1_xgb['Class'],pred_cost_train_cls1_xgb['predicted'])
train_precision_cost_class1_xgb = precision_score(pred_cost_train_cls1_xgb['Class'],pred_cost_train_cls1_xgb['predicted'])
train_recall_cost_class1_xgb = recall_score(pred_cost_train_cls1_xgb['Class'],pred_cost_train_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_cost_class1_xgb*100,2)," %")
print("precision of Class 1: ",round(train_precision_cost_class1_xgb*100,2)," %")
print("recall of Class 1: ",round(train_recall_cost_class1_xgb*100,2)," %")

"""On Testing Data"""

test_pred_cost_xgb = xgb_cost.predict(X_test_cost)
test_accuracy1_cost_xgb = accuracy_score(y_test_cost,test_pred_cost_xgb)
test_precision1_cost_xgb = precision_score(y_test_cost,test_pred_cost_xgb)
test_recall1_cost_xgb = recall_score(y_test_cost,test_pred_cost_xgb)


print("Accuracy on Testing Data is: ",round(test_accuracy1_cost_xgb*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_cost_xgb*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_cost_xgb*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_cost_xgb = confusion_matrix(y_test_cost,test_pred_cost_xgb)

cm_display_cost_xgb = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_cost_xgb, display_labels = ['Normal', 'Fraud'])

cm_display_cost_xgb.plot()
plt.title("Confusion Matrix - Cost Sensitive Learning -XGB- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_cost_xgb = RocCurveDisplay.from_estimator(xgb_cost,X_test_cost,y_test_cost)

"""Class wise Accuracy"""

pred_cost_test_xgb = pd.DataFrame(y_test_cost)
pred_cost_test_xgb['predicted'] = test_pred_cost_xgb

pred_cost_test_xgb

pred_cost_test_cls0_xgb = pred_cost_test_xgb[pred_cost_test_xgb['Class'] == 0]
pred_cost_test_cls1_xgb = pred_cost_test_xgb[pred_cost_test_xgb['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_cost_xgb = accuracy_score(pred_cost_test_cls0_xgb['Class'],pred_cost_test_cls0_xgb['predicted'])
test_precision_class0_cost_xgb = precision_score(pred_cost_test_cls0_xgb['Class'],pred_cost_test_cls0_xgb['predicted'])
test_recall_class0_cost_xgb = recall_score(pred_cost_test_cls0_xgb['Class'],pred_cost_test_cls0_xgb['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_cost_xgb*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_cost_xgb*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_cost_xgb*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_cost_xgb = accuracy_score(pred_cost_test_cls1_xgb['Class'],pred_cost_test_cls1_xgb['predicted'])
test_precision_class1_cost_xgb = precision_score(pred_cost_test_cls1_xgb['Class'],pred_cost_test_cls1_xgb['predicted'])
test_recall_class1_cost_xgb = recall_score(pred_cost_test_cls1_xgb['Class'],pred_cost_test_cls1_xgb['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_cost_xgb*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_cost_xgb*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_cost_xgb*100,2)," %")

"""### K Nearest Neighbor Classifier (KNN)



"""

from sklearn.neighbors import KNeighborsClassifier
knn_cost = KNeighborsClassifier(n_neighbors=3, weights='distance')

"""Training Dataset"""

knn_cost.fit(X_train_cost,y_train_cost)

"""####Evaluation

Accuracy Score , Precision , Recall and ROC-AUC score

On Training Data
"""

train_pred_cost_knn = knn_cost.predict(X_train_cost)
train_accuracy_cost_knn = accuracy_score(y_train_cost,train_pred_cost_knn)
train_precision_cost_knn = precision_score(y_train_cost,train_pred_cost_knn)
train_recall_cost_knn = recall_score(y_train_cost,train_pred_cost_knn)

print("Accuracy on Training Data is: ",round(train_accuracy_cost_knn*100,2)," %")
print("precision on Training Data is: ",round(train_precision_cost_knn*100,2)," %")
print("recall on Training Data is: ",round(train_recall_cost_knn*100,2)," %")

"""Classwise Accuracy"""

pred_cost_train_knn = pd.DataFrame(y_train_cost)
pred_cost_train_knn['predicted'] = train_pred_cost_knn
pred_cost_train_knn

pred_cost_train_cls0_knn = pred_cost_train_knn[pred_cost_train_knn['Class'] == 0]
pred_cost_train_cls1_knn = pred_cost_train_knn[pred_cost_train_knn['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

train_accuracy_cost_class0_knn = accuracy_score(pred_cost_train_cls0_knn['Class'],pred_cost_train_cls0_knn['predicted'])
train_precision_cost_class0_knn = precision_score(pred_cost_train_cls0_knn['Class'],pred_cost_train_cls0_knn['predicted'])
train_recall_cost_class0_knn = recall_score(pred_cost_train_cls0_knn['Class'],pred_cost_train_cls0_knn['predicted'])

print("Accuracy of Class 0: ",round(train_accuracy_cost_class0_knn*100,2)," %")
print("precision of Class 0: ",round(train_precision_cost_class0_knn*100,2)," %")
print("recall of Class 0: ",round(train_recall_cost_class0_knn*100,2)," %")

"""For class 1 i.e. Fraudulent Class"""

train_accuracy_cost_class1_knn = accuracy_score(pred_cost_train_cls1_knn['Class'],pred_cost_train_cls1_knn['predicted'])
train_precision_cost_class1_knn = precision_score(pred_cost_train_cls1_knn['Class'],pred_cost_train_cls1_knn['predicted'])
train_recall_cost_class1_knn = recall_score(pred_cost_train_cls1_knn['Class'],pred_cost_train_cls1_knn['predicted'])

print("Accuracy of Class 1: ",round(train_accuracy_cost_class1_knn*100,2)," %")
print("precision of Class 1: ",round(train_precision_cost_class1_knn*100,2)," %")
print("recall of Class 1: ",round(train_recall_cost_class1_knn*100,2)," %")

"""On Testing Data"""

test_pred_cost_knn = knn_cost.predict(X_test_cost)
test_accuracy1_cost_knn = accuracy_score(y_test_cost,test_pred_cost_knn)
test_precision1_cost_knn = precision_score(y_test_cost,test_pred_cost_knn)
test_recall1_cost_knn = recall_score(y_test_cost,test_pred_cost_knn)


print("Accuracy on Testing Data is: ",round(test_accuracy1_cost_knn*100,2)," %")
print("precision on Testing Data is: ",round(test_precision1_cost_knn*100,2)," %")
print("recall on Testing Data is: ",round(test_recall1_cost_knn*100,2)," %")

"""Confusion Matrix"""

confusion_matrix_cost_knn = confusion_matrix(y_test_cost,test_pred_cost_knn)

cm_display_cost_knn = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_cost_knn, display_labels = ['Normal', 'Fraud'])

cm_display_cost_knn.plot()
plt.title("Confusion Matrix - Cost Sensitive Learning -knn- Testing Dataset")
plt.grid(False)
plt.show()

"""ROC Curve"""

Roc_display_cost_knn = RocCurveDisplay.from_estimator(knn_cost,X_test_cost,y_test_cost)

"""Class wise Accuracy"""

pred_cost_test_knn = pd.DataFrame(y_test_cost)
pred_cost_test_knn['predicted'] = test_pred_cost_knn

pred_cost_test_knn

pred_cost_test_cls0_knn = pred_cost_test_knn[pred_cost_test_knn['Class'] == 0]
pred_cost_test_cls1_knn = pred_cost_test_knn[pred_cost_test_knn['Class'] == 1]

"""For class 0 i.e. Normal Transaction"""

test_accuracy_class0_cost_knn = accuracy_score(pred_cost_test_cls0_knn['Class'],pred_cost_test_cls0_knn['predicted'])
test_precision_class0_cost_knn = precision_score(pred_cost_test_cls0_knn['Class'],pred_cost_test_cls0_knn['predicted'])
test_recall_class0_cost_knn = recall_score(pred_cost_test_cls0_knn['Class'],pred_cost_test_cls0_knn['predicted'])

print("Accuracy of Class 0: ",round(test_accuracy_class0_cost_knn*100,2)," %")
print("precision of Class 0: ",round(test_precision_class0_cost_knn*100,2)," %")
print("recall of Class 0: ",round(test_recall_class0_cost_knn*100,2)," %")

"""For Class 1 i.e. Fraudulent Class"""

test_accuracy_class1_cost_knn = accuracy_score(pred_cost_test_cls1_knn['Class'],pred_cost_test_cls1_knn['predicted'])
test_precision_class1_cost_knn = precision_score(pred_cost_test_cls1_knn['Class'],pred_cost_test_cls1_knn['predicted'])
test_recall_class1_cost_knn = recall_score(pred_cost_test_cls1_knn['Class'],pred_cost_test_cls1_knn['predicted'])

print("Accuracy of Class 1: ",round(test_accuracy_class1_cost_knn*100,2)," %")
print("precision of Class 1: ",round(test_precision_class1_cost_knn*100,2)," %")
print("recall of Class 1: ",round(test_recall_class1_cost_knn*100,2)," %")

"""## Evaluation graphs"""

Model = ["Logistic Regression","Random Forest","XGB Classifier","K Nearest Neighbor"]

"""Accuracy Graph"""

Acc_cost_train_cls0 = [train_accuracy_cost_class0_logistic,train_accuracy_cost_class0_RF,train_accuracy_cost_class0_xgb,train_accuracy_cost_class0_knn]
Acc_cost_test_cls0 = [test_accuracy_class0_cost_logistic,test_accuracy_class0_cost_RF,test_accuracy_class0_cost_xgb,test_accuracy_class0_cost_knn]
Acc_cost_train_cls1 = [train_accuracy_cost_class1_logistic,train_accuracy_cost_class1_RF,train_accuracy_cost_class1_xgb,train_accuracy_cost_class1_knn]
Acc_cost_test_cls1 = [test_accuracy_class1_cost_logistic,test_accuracy_class1_cost_RF,test_accuracy_class1_cost_xgb,test_accuracy_class1_cost_knn]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_cost_train_cls0, label = "train class 0")
plt.scatter(Model,Acc_cost_train_cls0)

plt.plot(Model,Acc_cost_test_cls0, label = "test class 0")
plt.scatter(Model,Acc_cost_test_cls0)

plt.plot(Model,Acc_cost_train_cls1, label = "train class 1")
plt.scatter(Model,Acc_cost_train_cls1)

plt.plot(Model,Acc_cost_test_cls1, label = "test class 1")
plt.scatter(Model,Acc_cost_test_cls1)

plt.ylabel("Acc")
plt.xlabel("Model")
plt.title("Comparision of Model Acc - Cost Sensitive Learning")
plt.legend()
plt.show()

"""Precision Graph"""

Pre_cost_train_cls0 = [train_precision_cost_class0_logistic,train_precision_cost_class0_RF,train_precision_cost_class0_xgb,train_precision_cost_class0_knn]
Pre_cost_test_cls0 = [test_precision_class0_cost_logistic,test_precision_class0_cost_RF,test_precision_class0_cost_xgb,test_precision_class0_cost_knn]
Pre_cost_train_cls1 = [train_precision_cost_class1_logistic,train_precision_cost_class1_RF,train_precision_cost_class1_xgb,train_precision_cost_class1_knn]
Pre_cost_test_cls1 = [test_precision_class1_cost_logistic,test_precision_class1_cost_RF,test_precision_class1_cost_xgb,test_precision_class1_cost_knn]

plt.figure(figsize=(10,6))

plt.plot(Model,Pre_cost_train_cls0, label = "train class 0")
plt.scatter(Model,Pre_cost_train_cls0)

plt.plot(Model,Pre_cost_test_cls0, label = "test class 0")
plt.scatter(Model,Pre_cost_test_cls0)

plt.plot(Model,Pre_cost_train_cls1, label = "train class 1")
plt.scatter(Model,Pre_cost_train_cls1)

plt.plot(Model,Pre_cost_test_cls1, label = "test class 1")
plt.scatter(Model,Pre_cost_test_cls1)

plt.ylabel("Precision")
plt.xlabel("Model")
plt.title("Comparision of Model Precision - Cost Sensitive Learning")
plt.legend()
plt.show()

"""Recall Graph"""

Recall_cost_train_cls0 = [train_recall_cost_class0_logistic,train_recall_cost_class0_RF,train_recall_cost_class0_xgb,train_recall_cost_class0_knn]
Recall_cost_test_cls0 = [test_recall_class0_cost_logistic,test_recall_class0_cost_RF,test_recall_class0_cost_xgb,test_recall_class0_cost_knn]
Recall_cost_train_cls1 = [train_recall_cost_class1_logistic,train_recall_cost_class1_RF,train_recall_cost_class1_xgb,train_recall_cost_class1_knn]
Recall_cost_test_cls1 = [test_recall_class1_cost_logistic,test_recall_class1_cost_RF,test_recall_class1_cost_xgb,test_recall_class1_cost_knn]

plt.figure(figsize=(10,6))

plt.plot(Model,Recall_cost_train_cls0, label = "train class 0")
plt.scatter(Model,Recall_cost_train_cls0)

plt.plot(Model,Recall_cost_test_cls0, label = "test class 0")
plt.scatter(Model,Recall_cost_test_cls0)

plt.plot(Model,Recall_cost_train_cls1, label = "train class 1")
plt.scatter(Model,Recall_cost_train_cls1)

plt.plot(Model,Recall_cost_test_cls1, label = "test class 1")
plt.scatter(Model,Recall_cost_test_cls1)

plt.ylabel("Recall")
plt.xlabel("Model")
plt.title("Comparision of Model Recall - Cost Sensitive Learning")
plt.legend()
plt.show()

"""Evaluation Graphs for Class 1 (Fraudulent Transactions)"""

Acc_cost_test_cls1 = [test_accuracy_class1_cost_logistic,test_accuracy_class1_cost_RF,test_accuracy_class1_cost_xgb,test_accuracy_class1_cost_knn]
Pre_cost_test_cls1 = [test_precision_class1_cost_logistic,test_precision_class1_cost_RF,test_precision_class1_cost_xgb,test_precision_class1_cost_knn]
Recall_cost_test_cls1 = [test_recall_class1_cost_logistic,test_recall_class1_cost_RF,test_recall_class1_cost_xgb,test_recall_class1_cost_knn]

plt.figure(figsize=(10,6))

plt.plot(Model,Acc_cost_test_cls1,label = "Accuracy of Class 1")
plt.scatter(Model,Acc_cost_test_cls1)

plt.plot(Model,Pre_cost_test_cls1,label = "Precision of Class 1")
plt.scatter(Model,Pre_cost_test_cls1)

plt.plot(Model,Recall_cost_test_cls1,label = "Recall of Class 1")
plt.scatter(Model,Recall_cost_test_cls1)

plt.xlabel("Model")
plt.ylabel("value")
plt.title("Evaluation Metrics for Class 1")

plt.legend()
plt.show()